10/24/16 16:24:30 ******************************************************
10/24/16 16:24:30 ** condor_scheduniv_exec.382.0 (CONDOR_DAGMAN) STARTING UP
10/24/16 16:24:30 ** /usr/bin/condor_dagman
10/24/16 16:24:30 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
10/24/16 16:24:30 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
10/24/16 16:24:30 ** $CondorVersion: 8.4.8 Jun 30 2016 BuildID: 373513 $
10/24/16 16:24:30 ** $CondorPlatform: x86_64_Ubuntu14 $
10/24/16 16:24:30 ** PID = 18906
10/24/16 16:24:30 ** Log last touched time unavailable (No such file or directory)
10/24/16 16:24:30 ******************************************************
10/24/16 16:24:30 Using config source: /etc/condor/condor_config
10/24/16 16:24:30 Using local config sources: 
10/24/16 16:24:30    /etc/condor/condor_config.local
10/24/16 16:24:30 config Macros = 63, Sorted = 63, StringBytes = 2037, TablesBytes = 2308
10/24/16 16:24:30 CLASSAD_CACHING is ENABLED
10/24/16 16:24:30 Daemon Log is logging: D_ALWAYS D_ERROR
10/24/16 16:24:30 DaemonCore: No command port requested.
10/24/16 16:24:30 DAGMAN_USE_STRICT setting: 1
10/24/16 16:24:30 DAGMAN_VERBOSITY setting: 3
10/24/16 16:24:30 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
10/24/16 16:24:30 DAGMAN_DEBUG_CACHE_ENABLE setting: False
10/24/16 16:24:30 DAGMAN_SUBMIT_DELAY setting: 0
10/24/16 16:24:30 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
10/24/16 16:24:30 DAGMAN_STARTUP_CYCLE_DETECT setting: False
10/24/16 16:24:30 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
10/24/16 16:24:30 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
10/24/16 16:24:30 DAGMAN_DEFAULT_PRIORITY setting: 0
10/24/16 16:24:30 DAGMAN_SUPPRESS_NOTIFICATION setting: True
10/24/16 16:24:30 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
10/24/16 16:24:30 DAGMAN_RETRY_SUBMIT_FIRST setting: True
10/24/16 16:24:30 DAGMAN_RETRY_NODE_FIRST setting: False
10/24/16 16:24:30 DAGMAN_MAX_JOBS_IDLE setting: 1000
10/24/16 16:24:30 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
10/24/16 16:24:30 DAGMAN_MAX_PRE_SCRIPTS setting: 20
10/24/16 16:24:30 DAGMAN_MAX_POST_SCRIPTS setting: 20
10/24/16 16:24:30 DAGMAN_ALLOW_LOG_ERROR setting: False
10/24/16 16:24:30 DAGMAN_MUNGE_NODE_NAMES setting: True
10/24/16 16:24:30 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
10/24/16 16:24:30 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
10/24/16 16:24:30 DAGMAN_ALWAYS_RUN_POST setting: True
10/24/16 16:24:30 DAGMAN_ABORT_DUPLICATES setting: True
10/24/16 16:24:30 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
10/24/16 16:24:30 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
10/24/16 16:24:30 DAGMAN_AUTO_RESCUE setting: True
10/24/16 16:24:30 DAGMAN_MAX_RESCUE_NUM setting: 100
10/24/16 16:24:30 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
10/24/16 16:24:30 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
10/24/16 16:24:30 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
10/24/16 16:24:30 DAGMAN_MAX_JOB_HOLDS setting: 100
10/24/16 16:24:30 DAGMAN_HOLD_CLAIM_TIME setting: 20
10/24/16 16:24:30 ALL_DEBUG setting: 
10/24/16 16:24:30 DAGMAN_DEBUG setting: 
10/24/16 16:24:30 DAGMAN_SUPPRESS_JOB_LOGS setting: False
10/24/16 16:24:30 argv[0] == "condor_scheduniv_exec.382.0"
10/24/16 16:24:30 argv[1] == "-Lockfile"
10/24/16 16:24:30 argv[2] == "example_workflow-0.dag.lock"
10/24/16 16:24:30 argv[3] == "-AutoRescue"
10/24/16 16:24:30 argv[4] == "1"
10/24/16 16:24:30 argv[5] == "-DoRescueFrom"
10/24/16 16:24:30 argv[6] == "0"
10/24/16 16:24:30 argv[7] == "-Dag"
10/24/16 16:24:30 argv[8] == "example_workflow-0.dag"
10/24/16 16:24:30 argv[9] == "-MaxPost"
10/24/16 16:24:30 argv[10] == "20"
10/24/16 16:24:30 argv[11] == "-Suppress_notification"
10/24/16 16:24:30 argv[12] == "-CsdVersion"
10/24/16 16:24:30 argv[13] == "$CondorVersion: 8.4.8 Jun 30 2016 BuildID: 373513 $"
10/24/16 16:24:30 argv[14] == "-Dagman"
10/24/16 16:24:30 argv[15] == "/usr/bin/condor_dagman"
10/24/16 16:24:30 Warning: failed to get attribute DAGNodeName
10/24/16 16:24:30 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
10/24/16 16:24:30 Default node log file is: </home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log>
10/24/16 16:24:30 DAG Lockfile will be written to example_workflow-0.dag.lock
10/24/16 16:24:30 DAG Input file is example_workflow-0.dag
10/24/16 16:24:30 Parsing 1 dagfiles
10/24/16 16:24:30 Parsing example_workflow-0.dag ...
10/24/16 16:24:30 Warning: category stage-in has no throttle value set
10/24/16 16:24:30 Dag contains 39 total jobs
10/24/16 16:24:30 Sleeping for 3 seconds to ensure ProcessId uniqueness
10/24/16 16:24:33 Bootstrapping...
10/24/16 16:24:33 Number of pre-completed nodes: 0
10/24/16 16:24:33 MultiLogFiles: truncating log file /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:33 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:24:33 Of 39 nodes total:
10/24/16 16:24:33  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:24:33   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:24:33     0       0        0       0       1         38        0
10/24/16 16:24:33 0 job proc(s) currently held
10/24/16 16:24:33 Registering condor_event_timer...
10/24/16 16:24:34 Submitting Condor Node create_dir_example_workflow_0_local job(s)...
10/24/16 16:24:34 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:34 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:34 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:34 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'create_dir_example_workflow_0_local -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'create_dir_example_workflow_0_local -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/create_dir_example_workflow_0_local.sub
10/24/16 16:24:34 From submit: Submitting job(s).
10/24/16 16:24:34 From submit: 1 job(s) submitted to cluster 383.
10/24/16 16:24:34 	assigned Condor ID (383.0.0)
10/24/16 16:24:34 Just submitted 1 job this cycle...
10/24/16 16:24:34 Currently monitoring 1 Condor log file(s)
10/24/16 16:24:34 Reassigning the id of job create_dir_example_workflow_0_local from (383.0.0) to (383.0.0)
10/24/16 16:24:34 Event: ULOG_SUBMIT for Condor Node create_dir_example_workflow_0_local (383.0.0)
10/24/16 16:24:34 Number of idle job procs: 1
10/24/16 16:24:34 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:24:34 Of 39 nodes total:
10/24/16 16:24:34  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:24:34   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:24:34     0       0        1       0       0         38        0
10/24/16 16:24:34 0 job proc(s) currently held
10/24/16 16:24:39 Currently monitoring 1 Condor log file(s)
10/24/16 16:24:39 Event: ULOG_EXECUTE for Condor Node create_dir_example_workflow_0_local (383.0.0)
10/24/16 16:24:39 Number of idle job procs: 0
10/24/16 16:24:39 Event: ULOG_JOB_TERMINATED for Condor Node create_dir_example_workflow_0_local (383.0.0)
10/24/16 16:24:39 Number of idle job procs: 0
10/24/16 16:24:39 Node create_dir_example_workflow_0_local job proc (383.0.0) completed successfully.
10/24/16 16:24:39 Node create_dir_example_workflow_0_local job completed
10/24/16 16:24:39 Running POST script of Node create_dir_example_workflow_0_local...
10/24/16 16:24:39 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:24:39 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:24:39 Of 39 nodes total:
10/24/16 16:24:39  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:24:39   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:24:39     0       0        0       1       0         38        0
10/24/16 16:24:39 0 job proc(s) currently held
10/24/16 16:24:39 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (383.0.0)
10/24/16 16:24:44 Currently monitoring 1 Condor log file(s)
10/24/16 16:24:44 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node create_dir_example_workflow_0_local (383.0.0)
10/24/16 16:24:44 POST Script of Node create_dir_example_workflow_0_local completed successfully.
10/24/16 16:24:44 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:24:44 Of 39 nodes total:
10/24/16 16:24:44  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:24:44   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:24:44     1       0        0       0      18         20        0
10/24/16 16:24:44 0 job proc(s) currently held
10/24/16 16:24:49 Submitting Condor Node stage_in_local_local_0_0 job(s)...
10/24/16 16:24:49 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:49 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:49 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:49 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_0_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_0_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_0_0.sub
10/24/16 16:24:49 From submit: Submitting job(s).
10/24/16 16:24:49 From submit: 1 job(s) submitted to cluster 384.
10/24/16 16:24:49 	assigned Condor ID (384.0.0)
10/24/16 16:24:49 Submitting Condor Node stage_in_local_local_6_0 job(s)...
10/24/16 16:24:49 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:49 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:49 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:49 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_6_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_6_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_6_0.sub
10/24/16 16:24:49 From submit: Submitting job(s).
10/24/16 16:24:49 From submit: 1 job(s) submitted to cluster 385.
10/24/16 16:24:49 	assigned Condor ID (385.0.0)
10/24/16 16:24:49 Submitting Condor Node stage_in_remote_local_2_1 job(s)...
10/24/16 16:24:49 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:49 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:49 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:49 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_2_1 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_2_1 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_2_1.sub
10/24/16 16:24:49 From submit: Submitting job(s).
10/24/16 16:24:49 From submit: 1 job(s) submitted to cluster 386.
10/24/16 16:24:49 	assigned Condor ID (386.0.0)
10/24/16 16:24:49 Submitting Condor Node stage_in_remote_local_5_0 job(s)...
10/24/16 16:24:49 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:49 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:49 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:49 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_5_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_5_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_5_0.sub
10/24/16 16:24:49 From submit: Submitting job(s).
10/24/16 16:24:49 From submit: 1 job(s) submitted to cluster 387.
10/24/16 16:24:50 	assigned Condor ID (387.0.0)
10/24/16 16:24:50 Submitting Condor Node stage_in_local_local_2_0 job(s)...
10/24/16 16:24:50 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:50 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:50 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:50 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_2_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_2_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_2_0.sub
10/24/16 16:24:50 From submit: Submitting job(s).
10/24/16 16:24:50 From submit: 1 job(s) submitted to cluster 388.
10/24/16 16:24:50 	assigned Condor ID (388.0.0)
10/24/16 16:24:50 Just submitted 5 jobs this cycle...
10/24/16 16:24:50 Currently monitoring 1 Condor log file(s)
10/24/16 16:24:50 Reassigning the id of job stage_in_local_local_0_0 from (384.0.0) to (384.0.0)
10/24/16 16:24:50 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_0_0 (384.0.0)
10/24/16 16:24:50 Number of idle job procs: 1
10/24/16 16:24:50 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_0_0 (384.0.0)
10/24/16 16:24:50 Number of idle job procs: 0
10/24/16 16:24:50 Reassigning the id of job stage_in_local_local_6_0 from (385.0.0) to (385.0.0)
10/24/16 16:24:50 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_6_0 (385.0.0)
10/24/16 16:24:50 Number of idle job procs: 1
10/24/16 16:24:50 Reassigning the id of job stage_in_remote_local_2_1 from (386.0.0) to (386.0.0)
10/24/16 16:24:50 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_2_1 (386.0.0)
10/24/16 16:24:50 Number of idle job procs: 2
10/24/16 16:24:50 Reassigning the id of job stage_in_remote_local_5_0 from (387.0.0) to (387.0.0)
10/24/16 16:24:50 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_5_0 (387.0.0)
10/24/16 16:24:50 Number of idle job procs: 3
10/24/16 16:24:50 Reassigning the id of job stage_in_local_local_2_0 from (388.0.0) to (388.0.0)
10/24/16 16:24:50 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_2_0 (388.0.0)
10/24/16 16:24:50 Number of idle job procs: 4
10/24/16 16:24:50 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:24:50 Of 39 nodes total:
10/24/16 16:24:50  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:24:50   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:24:50     1       0        5       0      13         20        0
10/24/16 16:24:50 0 job proc(s) currently held
10/24/16 16:24:55 Submitting Condor Node stage_in_local_local_2_1 job(s)...
10/24/16 16:24:55 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:55 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:55 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:55 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_2_1 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_2_1 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_2_1.sub
10/24/16 16:24:55 From submit: Submitting job(s).
10/24/16 16:24:55 From submit: 1 job(s) submitted to cluster 389.
10/24/16 16:24:55 	assigned Condor ID (389.0.0)
10/24/16 16:24:55 Submitting Condor Node stage_in_remote_local_1_0 job(s)...
10/24/16 16:24:55 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:55 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:55 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:55 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_1_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_1_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_1_0.sub
10/24/16 16:24:55 From submit: Submitting job(s).
10/24/16 16:24:55 From submit: 1 job(s) submitted to cluster 390.
10/24/16 16:24:55 	assigned Condor ID (390.0.0)
10/24/16 16:24:55 Submitting Condor Node stage_in_local_local_3_0 job(s)...
10/24/16 16:24:55 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:55 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:55 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:55 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_3_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_3_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_3_0.sub
10/24/16 16:24:55 From submit: Submitting job(s).
10/24/16 16:24:55 From submit: 1 job(s) submitted to cluster 391.
10/24/16 16:24:55 	assigned Condor ID (391.0.0)
10/24/16 16:24:55 Submitting Condor Node stage_in_local_local_5_0 job(s)...
10/24/16 16:24:55 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:55 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:55 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:55 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_5_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_5_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_5_0.sub
10/24/16 16:24:55 From submit: Submitting job(s).
10/24/16 16:24:55 From submit: 1 job(s) submitted to cluster 392.
10/24/16 16:24:55 	assigned Condor ID (392.0.0)
10/24/16 16:24:55 Submitting Condor Node stage_in_local_local_4_0 job(s)...
10/24/16 16:24:55 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:24:55 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:24:55 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:24:55 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_4_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_4_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_4_0.sub
10/24/16 16:24:55 From submit: Submitting job(s).
10/24/16 16:24:55 From submit: 1 job(s) submitted to cluster 393.
10/24/16 16:24:55 	assigned Condor ID (393.0.0)
10/24/16 16:24:55 Just submitted 5 jobs this cycle...
10/24/16 16:24:55 Currently monitoring 1 Condor log file(s)
10/24/16 16:24:55 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_0_0 (384.0.0)
10/24/16 16:24:55 Number of idle job procs: 4
10/24/16 16:24:55 Node stage_in_local_local_0_0 job proc (384.0.0) completed successfully.
10/24/16 16:24:55 Node stage_in_local_local_0_0 job completed
10/24/16 16:24:55 Running POST script of Node stage_in_local_local_0_0...
10/24/16 16:24:55 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:24:55 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_5_0 (387.0.0)
10/24/16 16:24:55 Number of idle job procs: 3
10/24/16 16:24:55 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_2_1 (386.0.0)
10/24/16 16:24:55 Number of idle job procs: 2
10/24/16 16:24:55 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_6_0 (385.0.0)
10/24/16 16:24:55 Number of idle job procs: 1
10/24/16 16:24:55 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_2_0 (388.0.0)
10/24/16 16:24:55 Number of idle job procs: 0
10/24/16 16:24:55 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_6_0 (385.0.0)
10/24/16 16:24:55 Number of idle job procs: 0
10/24/16 16:24:55 Node stage_in_local_local_6_0 job proc (385.0.0) completed successfully.
10/24/16 16:24:55 Node stage_in_local_local_6_0 job completed
10/24/16 16:24:55 Running POST script of Node stage_in_local_local_6_0...
10/24/16 16:24:55 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:24:55 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_5_0 (387.0.0)
10/24/16 16:24:55 Number of idle job procs: 0
10/24/16 16:24:55 Node stage_in_remote_local_5_0 job proc (387.0.0) completed successfully.
10/24/16 16:24:55 Node stage_in_remote_local_5_0 job completed
10/24/16 16:24:55 Running POST script of Node stage_in_remote_local_5_0...
10/24/16 16:24:55 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:24:55 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_2_1 (386.0.0)
10/24/16 16:24:55 Number of idle job procs: 0
10/24/16 16:24:55 Node stage_in_remote_local_2_1 job proc (386.0.0) completed successfully.
10/24/16 16:24:55 Node stage_in_remote_local_2_1 job completed
10/24/16 16:24:55 Running POST script of Node stage_in_remote_local_2_1...
10/24/16 16:24:55 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:24:55 Reassigning the id of job stage_in_local_local_2_1 from (389.0.0) to (389.0.0)
10/24/16 16:24:55 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_2_1 (389.0.0)
10/24/16 16:24:55 Number of idle job procs: 1
10/24/16 16:24:55 Reassigning the id of job stage_in_remote_local_1_0 from (390.0.0) to (390.0.0)
10/24/16 16:24:55 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_1_0 (390.0.0)
10/24/16 16:24:55 Number of idle job procs: 2
10/24/16 16:24:55 Reassigning the id of job stage_in_local_local_3_0 from (391.0.0) to (391.0.0)
10/24/16 16:24:55 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_3_0 (391.0.0)
10/24/16 16:24:55 Number of idle job procs: 3
10/24/16 16:24:55 Reassigning the id of job stage_in_local_local_5_0 from (392.0.0) to (392.0.0)
10/24/16 16:24:55 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_5_0 (392.0.0)
10/24/16 16:24:55 Number of idle job procs: 4
10/24/16 16:24:55 Reassigning the id of job stage_in_local_local_4_0 from (393.0.0) to (393.0.0)
10/24/16 16:24:55 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_4_0 (393.0.0)
10/24/16 16:24:55 Number of idle job procs: 5
10/24/16 16:24:55 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:24:55 Of 39 nodes total:
10/24/16 16:24:55  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:24:55   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:24:55     1       0        6       4       8         20        0
10/24/16 16:24:55 0 job proc(s) currently held
10/24/16 16:24:55 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (384.0.0)
10/24/16 16:24:55 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (387.0.0)
10/24/16 16:24:55 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (385.0.0)
10/24/16 16:24:55 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (386.0.0)
10/24/16 16:25:00 Submitting Condor Node stage_in_local_local_7_0 job(s)...
10/24/16 16:25:00 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:00 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:00 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:00 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_7_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_7_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_7_0.sub
10/24/16 16:25:00 From submit: Submitting job(s).
10/24/16 16:25:00 From submit: 1 job(s) submitted to cluster 394.
10/24/16 16:25:00 	assigned Condor ID (394.0.0)
10/24/16 16:25:00 Submitting Condor Node stage_in_local_local_1_0 job(s)...
10/24/16 16:25:00 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:00 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:00 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:00 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_1_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_1_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_1_0.sub
10/24/16 16:25:01 From submit: Submitting job(s).
10/24/16 16:25:01 From submit: 1 job(s) submitted to cluster 395.
10/24/16 16:25:01 	assigned Condor ID (395.0.0)
10/24/16 16:25:01 Submitting Condor Node stage_in_remote_local_4_1 job(s)...
10/24/16 16:25:01 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:01 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:01 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:01 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_4_1 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_4_1 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_4_1.sub
10/24/16 16:25:01 From submit: Submitting job(s).
10/24/16 16:25:01 From submit: 1 job(s) submitted to cluster 396.
10/24/16 16:25:01 	assigned Condor ID (396.0.0)
10/24/16 16:25:01 Submitting Condor Node stage_in_remote_local_4_0 job(s)...
10/24/16 16:25:01 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:01 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:01 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:01 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_4_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_4_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_4_0.sub
10/24/16 16:25:01 From submit: Submitting job(s).
10/24/16 16:25:01 From submit: 1 job(s) submitted to cluster 397.
10/24/16 16:25:01 	assigned Condor ID (397.0.0)
10/24/16 16:25:01 Submitting Condor Node stage_in_remote_local_2_0 job(s)...
10/24/16 16:25:01 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:01 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:01 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:01 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_2_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_2_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_2_0.sub
10/24/16 16:25:01 From submit: Submitting job(s).
10/24/16 16:25:01 From submit: 1 job(s) submitted to cluster 398.
10/24/16 16:25:01 	assigned Condor ID (398.0.0)
10/24/16 16:25:01 Just submitted 5 jobs this cycle...
10/24/16 16:25:01 Currently monitoring 1 Condor log file(s)
10/24/16 16:25:01 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_0_0 (384.0.0)
10/24/16 16:25:01 POST Script of Node stage_in_local_local_0_0 completed successfully.
10/24/16 16:25:01 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_5_0 (387.0.0)
10/24/16 16:25:01 POST Script of Node stage_in_remote_local_5_0 completed successfully.
10/24/16 16:25:01 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_6_0 (385.0.0)
10/24/16 16:25:01 POST Script of Node stage_in_local_local_6_0 completed successfully.
10/24/16 16:25:01 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_2_1 (386.0.0)
10/24/16 16:25:01 POST Script of Node stage_in_remote_local_2_1 completed successfully.
10/24/16 16:25:01 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_2_0 (388.0.0)
10/24/16 16:25:01 Number of idle job procs: 5
10/24/16 16:25:01 Node stage_in_local_local_2_0 job proc (388.0.0) completed successfully.
10/24/16 16:25:01 Node stage_in_local_local_2_0 job completed
10/24/16 16:25:01 Running POST script of Node stage_in_local_local_2_0...
10/24/16 16:25:01 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:01 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_1_0 (390.0.0)
10/24/16 16:25:01 Number of idle job procs: 4
10/24/16 16:25:01 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_2_1 (389.0.0)
10/24/16 16:25:01 Number of idle job procs: 3
10/24/16 16:25:01 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_4_0 (393.0.0)
10/24/16 16:25:01 Number of idle job procs: 2
10/24/16 16:25:01 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_5_0 (392.0.0)
10/24/16 16:25:01 Number of idle job procs: 1
10/24/16 16:25:01 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_3_0 (391.0.0)
10/24/16 16:25:01 Number of idle job procs: 0
10/24/16 16:25:01 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_1_0 (390.0.0)
10/24/16 16:25:01 Number of idle job procs: 0
10/24/16 16:25:01 Node stage_in_remote_local_1_0 job proc (390.0.0) completed successfully.
10/24/16 16:25:01 Node stage_in_remote_local_1_0 job completed
10/24/16 16:25:01 Running POST script of Node stage_in_remote_local_1_0...
10/24/16 16:25:01 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:01 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_2_1 (389.0.0)
10/24/16 16:25:01 Number of idle job procs: 0
10/24/16 16:25:01 Node stage_in_local_local_2_1 job proc (389.0.0) completed successfully.
10/24/16 16:25:01 Node stage_in_local_local_2_1 job completed
10/24/16 16:25:01 Running POST script of Node stage_in_local_local_2_1...
10/24/16 16:25:01 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:01 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_5_0 (392.0.0)
10/24/16 16:25:01 Number of idle job procs: 0
10/24/16 16:25:01 Node stage_in_local_local_5_0 job proc (392.0.0) completed successfully.
10/24/16 16:25:01 Node stage_in_local_local_5_0 job completed
10/24/16 16:25:01 Running POST script of Node stage_in_local_local_5_0...
10/24/16 16:25:01 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:01 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_4_0 (393.0.0)
10/24/16 16:25:01 Number of idle job procs: 0
10/24/16 16:25:01 Node stage_in_local_local_4_0 job proc (393.0.0) completed successfully.
10/24/16 16:25:01 Node stage_in_local_local_4_0 job completed
10/24/16 16:25:01 Running POST script of Node stage_in_local_local_4_0...
10/24/16 16:25:01 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:01 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_3_0 (391.0.0)
10/24/16 16:25:01 Number of idle job procs: 0
10/24/16 16:25:01 Node stage_in_local_local_3_0 job proc (391.0.0) completed successfully.
10/24/16 16:25:01 Node stage_in_local_local_3_0 job completed
10/24/16 16:25:01 Running POST script of Node stage_in_local_local_3_0...
10/24/16 16:25:01 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:01 Reassigning the id of job stage_in_local_local_7_0 from (394.0.0) to (394.0.0)
10/24/16 16:25:01 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_7_0 (394.0.0)
10/24/16 16:25:01 Number of idle job procs: 1
10/24/16 16:25:01 Reassigning the id of job stage_in_local_local_1_0 from (395.0.0) to (395.0.0)
10/24/16 16:25:01 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_1_0 (395.0.0)
10/24/16 16:25:01 Number of idle job procs: 2
10/24/16 16:25:01 Reassigning the id of job stage_in_remote_local_4_1 from (396.0.0) to (396.0.0)
10/24/16 16:25:01 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_4_1 (396.0.0)
10/24/16 16:25:01 Number of idle job procs: 3
10/24/16 16:25:01 Reassigning the id of job stage_in_remote_local_4_0 from (397.0.0) to (397.0.0)
10/24/16 16:25:01 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_4_0 (397.0.0)
10/24/16 16:25:01 Number of idle job procs: 4
10/24/16 16:25:01 Reassigning the id of job stage_in_remote_local_2_0 from (398.0.0) to (398.0.0)
10/24/16 16:25:01 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_2_0 (398.0.0)
10/24/16 16:25:01 Number of idle job procs: 5
10/24/16 16:25:01 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:25:01 Of 39 nodes total:
10/24/16 16:25:01  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:25:01   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:25:01     5       0        5       6       4         19        0
10/24/16 16:25:01 0 job proc(s) currently held
10/24/16 16:25:01 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (388.0.0)
10/24/16 16:25:01 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (390.0.0)
10/24/16 16:25:01 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (392.0.0)
10/24/16 16:25:02 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (391.0.0)
10/24/16 16:25:02 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (393.0.0)
10/24/16 16:25:02 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (389.0.0)
10/24/16 16:25:06 Submitting Condor Node stage_in_remote_local_3_1 job(s)...
10/24/16 16:25:06 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:06 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:06 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:06 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_3_1 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_3_1 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_3_1.sub
10/24/16 16:25:06 From submit: Submitting job(s).
10/24/16 16:25:06 From submit: 1 job(s) submitted to cluster 399.
10/24/16 16:25:06 	assigned Condor ID (399.0.0)
10/24/16 16:25:06 Submitting Condor Node stage_in_remote_local_3_0 job(s)...
10/24/16 16:25:06 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:06 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:06 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:06 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_3_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_3_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_3_0.sub
10/24/16 16:25:06 From submit: Submitting job(s).
10/24/16 16:25:06 From submit: 1 job(s) submitted to cluster 400.
10/24/16 16:25:06 	assigned Condor ID (400.0.0)
10/24/16 16:25:06 Submitting Condor Node stage_in_remote_local_6_0 job(s)...
10/24/16 16:25:06 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:06 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:06 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:06 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_6_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_6_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_6_0.sub
10/24/16 16:25:06 From submit: Submitting job(s).
10/24/16 16:25:06 From submit: 1 job(s) submitted to cluster 401.
10/24/16 16:25:06 	assigned Condor ID (401.0.0)
10/24/16 16:25:06 Submitting Condor Node init_0_ID0000001 job(s)...
10/24/16 16:25:06 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:25:06 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:25:06 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:25:06 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'init_0_ID0000001 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'init_0_ID0000001 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_0_0" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/init_0_ID0000001.sub
10/24/16 16:25:06 From submit: Submitting job(s).
10/24/16 16:25:06 From submit: 1 job(s) submitted to cluster 402.
10/24/16 16:25:06 	assigned Condor ID (402.0.0)
10/24/16 16:25:06 Just submitted 4 jobs this cycle...
10/24/16 16:25:06 Currently monitoring 1 Condor log file(s)
10/24/16 16:25:06 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_2_0 (388.0.0)
10/24/16 16:25:06 POST Script of Node stage_in_local_local_2_0 completed successfully.
10/24/16 16:25:06 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_1_0 (390.0.0)
10/24/16 16:25:06 POST Script of Node stage_in_remote_local_1_0 completed successfully.
10/24/16 16:25:06 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_5_0 (392.0.0)
10/24/16 16:25:06 POST Script of Node stage_in_local_local_5_0 completed successfully.
10/24/16 16:25:06 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_3_0 (391.0.0)
10/24/16 16:25:06 POST Script of Node stage_in_local_local_3_0 completed successfully.
10/24/16 16:25:06 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_4_0 (393.0.0)
10/24/16 16:25:06 POST Script of Node stage_in_local_local_4_0 completed successfully.
10/24/16 16:25:06 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_2_1 (389.0.0)
10/24/16 16:25:06 POST Script of Node stage_in_local_local_2_1 completed successfully.
10/24/16 16:25:06 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_4_1 (396.0.0)
10/24/16 16:25:06 Number of idle job procs: 4
10/24/16 16:25:06 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_1_0 (395.0.0)
10/24/16 16:25:06 Number of idle job procs: 3
10/24/16 16:25:06 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_2_0 (398.0.0)
10/24/16 16:25:06 Number of idle job procs: 2
10/24/16 16:25:06 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_7_0 (394.0.0)
10/24/16 16:25:06 Number of idle job procs: 1
10/24/16 16:25:06 Reassigning the id of job stage_in_remote_local_3_1 from (399.0.0) to (399.0.0)
10/24/16 16:25:06 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_3_1 (399.0.0)
10/24/16 16:25:06 Number of idle job procs: 2
10/24/16 16:25:06 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_4_0 (397.0.0)
10/24/16 16:25:06 Number of idle job procs: 1
10/24/16 16:25:06 Reassigning the id of job stage_in_remote_local_3_0 from (400.0.0) to (400.0.0)
10/24/16 16:25:06 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_3_0 (400.0.0)
10/24/16 16:25:06 Number of idle job procs: 2
10/24/16 16:25:06 Reassigning the id of job stage_in_remote_local_6_0 from (401.0.0) to (401.0.0)
10/24/16 16:25:06 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_6_0 (401.0.0)
10/24/16 16:25:06 Number of idle job procs: 3
10/24/16 16:25:06 Reassigning the id of job init_0_ID0000001 from (402.0.0) to (402.0.0)
10/24/16 16:25:06 Event: ULOG_SUBMIT for Condor Node init_0_ID0000001 (402.0.0)
10/24/16 16:25:06 Number of idle job procs: 4
10/24/16 16:25:06 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:25:06 Of 39 nodes total:
10/24/16 16:25:06  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:25:06   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:25:06    11       0        9       0       0         19        0
10/24/16 16:25:06 0 job proc(s) currently held
10/24/16 16:25:12 Currently monitoring 1 Condor log file(s)
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_4_1 (396.0.0)
10/24/16 16:25:12 Number of idle job procs: 4
10/24/16 16:25:12 Node stage_in_remote_local_4_1 job proc (396.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_remote_local_4_1 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_remote_local_4_1...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_7_0 (394.0.0)
10/24/16 16:25:12 Number of idle job procs: 4
10/24/16 16:25:12 Node stage_in_local_local_7_0 job proc (394.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_local_local_7_0 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_local_local_7_0...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_3_0 (400.0.0)
10/24/16 16:25:12 Number of idle job procs: 3
10/24/16 16:25:12 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_3_1 (399.0.0)
10/24/16 16:25:12 Number of idle job procs: 2
10/24/16 16:25:12 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_6_0 (401.0.0)
10/24/16 16:25:12 Number of idle job procs: 1
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_1_0 (395.0.0)
10/24/16 16:25:12 Number of idle job procs: 1
10/24/16 16:25:12 Node stage_in_local_local_1_0 job proc (395.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_local_local_1_0 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_local_local_1_0...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_4_0 (397.0.0)
10/24/16 16:25:12 Number of idle job procs: 1
10/24/16 16:25:12 Node stage_in_remote_local_4_0 job proc (397.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_remote_local_4_0 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_remote_local_4_0...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_2_0 (398.0.0)
10/24/16 16:25:12 Number of idle job procs: 1
10/24/16 16:25:12 Node stage_in_remote_local_2_0 job proc (398.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_remote_local_2_0 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_remote_local_2_0...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_6_0 (401.0.0)
10/24/16 16:25:12 Number of idle job procs: 1
10/24/16 16:25:12 Node stage_in_remote_local_6_0 job proc (401.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_remote_local_6_0 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_remote_local_6_0...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_3_1 (399.0.0)
10/24/16 16:25:12 Number of idle job procs: 1
10/24/16 16:25:12 Node stage_in_remote_local_3_1 job proc (399.0.0) completed successfully.
10/24/16 16:25:12 Node stage_in_remote_local_3_1 job completed
10/24/16 16:25:12 Running POST script of Node stage_in_remote_local_3_1...
10/24/16 16:25:12 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:12 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:25:12 Of 39 nodes total:
10/24/16 16:25:12  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:25:12   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:25:12    11       0        2       7       0         19        0
10/24/16 16:25:12 0 job proc(s) currently held
10/24/16 16:25:12 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (395.0.0)
10/24/16 16:25:12 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (396.0.0)
10/24/16 16:25:12 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (394.0.0)
10/24/16 16:25:12 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (401.0.0)
10/24/16 16:25:12 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (398.0.0)
10/24/16 16:25:13 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (397.0.0)
10/24/16 16:25:13 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (399.0.0)
10/24/16 16:25:17 Currently monitoring 1 Condor log file(s)
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_1_0 (395.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_local_local_1_0 completed successfully.
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_4_1 (396.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_remote_local_4_1 completed successfully.
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_7_0 (394.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_local_local_7_0 completed successfully.
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_6_0 (401.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_remote_local_6_0 completed successfully.
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_2_0 (398.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_remote_local_2_0 completed successfully.
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_4_0 (397.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_remote_local_4_0 completed successfully.
10/24/16 16:25:17 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_3_1 (399.0.0)
10/24/16 16:25:17 POST Script of Node stage_in_remote_local_3_1 completed successfully.
10/24/16 16:25:17 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_3_0 (400.0.0)
10/24/16 16:25:17 Number of idle job procs: 1
10/24/16 16:25:17 Node stage_in_remote_local_3_0 job proc (400.0.0) completed successfully.
10/24/16 16:25:17 Node stage_in_remote_local_3_0 job completed
10/24/16 16:25:17 Running POST script of Node stage_in_remote_local_3_0...
10/24/16 16:25:17 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:25:17 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:25:17 Of 39 nodes total:
10/24/16 16:25:17  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:25:17   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:25:17    18       0        1       1       0         19        0
10/24/16 16:25:17 0 job proc(s) currently held
10/24/16 16:25:17 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (400.0.0)
10/24/16 16:25:22 Currently monitoring 1 Condor log file(s)
10/24/16 16:25:22 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_3_0 (400.0.0)
10/24/16 16:25:22 POST Script of Node stage_in_remote_local_3_0 completed successfully.
10/24/16 16:25:22 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:25:22 Of 39 nodes total:
10/24/16 16:25:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:25:22   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:25:22    19       0        1       0       0         19        0
10/24/16 16:25:22 0 job proc(s) currently held
10/24/16 16:25:32 Currently monitoring 1 Condor log file(s)
10/24/16 16:25:32 Event: ULOG_EXECUTE for Condor Node init_0_ID0000001 (402.0.0)
10/24/16 16:25:32 Number of idle job procs: 0
10/24/16 16:26:17 Currently monitoring 1 Condor log file(s)
10/24/16 16:26:17 Event: ULOG_JOB_TERMINATED for Condor Node init_0_ID0000001 (402.0.0)
10/24/16 16:26:17 Number of idle job procs: 0
10/24/16 16:26:17 Node init_0_ID0000001 job proc (402.0.0) completed successfully.
10/24/16 16:26:17 Node init_0_ID0000001 job completed
10/24/16 16:26:17 Running POST script of Node init_0_ID0000001...
10/24/16 16:26:17 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:26:17 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:26:17 Of 39 nodes total:
10/24/16 16:26:17  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:26:17   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:26:17    19       0        0       1       0         19        0
10/24/16 16:26:17 0 job proc(s) currently held
10/24/16 16:26:17 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (402.0.0)
10/24/16 16:26:22 Currently monitoring 1 Condor log file(s)
10/24/16 16:26:22 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node init_0_ID0000001 (402.0.0)
10/24/16 16:26:22 POST Script of Node init_0_ID0000001 completed successfully.
10/24/16 16:26:22 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:26:22 Of 39 nodes total:
10/24/16 16:26:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:26:22   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:26:22    20       0        0       0       2         17        0
10/24/16 16:26:22 0 job proc(s) currently held
10/24/16 16:26:27 Submitting Condor Node clean_up_local_level_3_0 job(s)...
10/24/16 16:26:27 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:26:27 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:26:27 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:26:27 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_3_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_3_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"init_0_ID0000001" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_3_0.sub
10/24/16 16:26:27 From submit: Submitting job(s).
10/24/16 16:26:27 From submit: 1 job(s) submitted to cluster 403.
10/24/16 16:26:27 	assigned Condor ID (403.0.0)
10/24/16 16:26:27 Submitting Condor Node generalinfo_0_ID0000002 job(s)...
10/24/16 16:26:27 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:26:27 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:26:27 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:26:27 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'generalinfo_0_ID0000002 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'generalinfo_0_ID0000002 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_remote_local_1_0,stage_in_local_local_1_0,init_0_ID0000001" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/generalinfo_0_ID0000002.sub
10/24/16 16:26:27 From submit: Submitting job(s).
10/24/16 16:26:27 From submit: 1 job(s) submitted to cluster 404.
10/24/16 16:26:27 	assigned Condor ID (404.0.0)
10/24/16 16:26:27 Just submitted 2 jobs this cycle...
10/24/16 16:26:27 Currently monitoring 1 Condor log file(s)
10/24/16 16:26:27 Reassigning the id of job clean_up_local_level_3_0 from (403.0.0) to (403.0.0)
10/24/16 16:26:27 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_3_0 (403.0.0)
10/24/16 16:26:27 Number of idle job procs: 1
10/24/16 16:26:27 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_3_0 (403.0.0)
10/24/16 16:26:27 Number of idle job procs: 0
10/24/16 16:26:27 Reassigning the id of job generalinfo_0_ID0000002 from (404.0.0) to (404.0.0)
10/24/16 16:26:27 Event: ULOG_SUBMIT for Condor Node generalinfo_0_ID0000002 (404.0.0)
10/24/16 16:26:27 Number of idle job procs: 1
10/24/16 16:26:27 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:26:27 Of 39 nodes total:
10/24/16 16:26:27  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:26:27   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:26:27    20       0        2       0       0         17        0
10/24/16 16:26:27 0 job proc(s) currently held
10/24/16 16:26:32 Currently monitoring 1 Condor log file(s)
10/24/16 16:26:32 Event: ULOG_EXECUTE for Condor Node generalinfo_0_ID0000002 (404.0.0)
10/24/16 16:26:32 Number of idle job procs: 0
10/24/16 16:26:32 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_3_0 (403.0.0)
10/24/16 16:26:32 Number of idle job procs: 0
10/24/16 16:26:32 Node clean_up_local_level_3_0 job proc (403.0.0) completed successfully.
10/24/16 16:26:32 Node clean_up_local_level_3_0 job completed
10/24/16 16:26:32 Running POST script of Node clean_up_local_level_3_0...
10/24/16 16:26:32 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:26:32 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:26:32 Of 39 nodes total:
10/24/16 16:26:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:26:32   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:26:32    20       0        1       1       0         17        0
10/24/16 16:26:32 0 job proc(s) currently held
10/24/16 16:26:32 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (403.0.0)
10/24/16 16:26:37 Currently monitoring 1 Condor log file(s)
10/24/16 16:26:37 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_3_0 (403.0.0)
10/24/16 16:26:37 POST Script of Node clean_up_local_level_3_0 completed successfully.
10/24/16 16:26:37 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:26:37 Of 39 nodes total:
10/24/16 16:26:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:26:37   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:26:37    21       0        1       0       0         17        0
10/24/16 16:26:37 0 job proc(s) currently held
10/24/16 16:30:43 Currently monitoring 1 Condor log file(s)
10/24/16 16:30:43 Event: ULOG_JOB_TERMINATED for Condor Node generalinfo_0_ID0000002 (404.0.0)
10/24/16 16:30:43 Number of idle job procs: 0
10/24/16 16:30:43 Node generalinfo_0_ID0000002 job proc (404.0.0) completed successfully.
10/24/16 16:30:43 Node generalinfo_0_ID0000002 job completed
10/24/16 16:30:43 Running POST script of Node generalinfo_0_ID0000002...
10/24/16 16:30:43 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:30:43 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:30:43 Of 39 nodes total:
10/24/16 16:30:43  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:30:43   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:30:43    21       0        0       1       0         17        0
10/24/16 16:30:43 0 job proc(s) currently held
10/24/16 16:30:43 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (404.0.0)
10/24/16 16:30:48 Currently monitoring 1 Condor log file(s)
10/24/16 16:30:48 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node generalinfo_0_ID0000002 (404.0.0)
10/24/16 16:30:48 POST Script of Node generalinfo_0_ID0000002 completed successfully.
10/24/16 16:30:48 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:30:48 Of 39 nodes total:
10/24/16 16:30:48  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:30:48   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:30:48    22       0        0       0       4         13        0
10/24/16 16:30:48 0 job proc(s) currently held
10/24/16 16:30:53 Submitting Condor Node clean_up_local_level_4_0 job(s)...
10/24/16 16:30:53 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:30:53 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:30:53 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:30:53 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_4_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_4_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"generalinfo_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_4_0.sub
10/24/16 16:30:53 From submit: Submitting job(s).
10/24/16 16:30:53 From submit: 1 job(s) submitted to cluster 405.
10/24/16 16:30:53 	assigned Condor ID (405.0.0)
10/24/16 16:30:53 Submitting Condor Node statscpumemory_0_ID0000003 job(s)...
10/24/16 16:30:53 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:30:53 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:30:53 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:30:53 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'statscpumemory_0_ID0000003 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'statscpumemory_0_ID0000003 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_2_0,stage_in_remote_local_2_0,generalinfo_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/statscpumemory_0_ID0000003.sub
10/24/16 16:30:53 From submit: Submitting job(s).
10/24/16 16:30:53 From submit: 1 job(s) submitted to cluster 406.
10/24/16 16:30:53 	assigned Condor ID (406.0.0)
10/24/16 16:30:53 Submitting Condor Node medianmemory_0_ID0000005 job(s)...
10/24/16 16:30:53 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:30:53 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:30:53 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:30:53 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'medianmemory_0_ID0000005 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'medianmemory_0_ID0000005 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_remote_local_2_1,stage_in_local_local_2_1,generalinfo_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/medianmemory_0_ID0000005.sub
10/24/16 16:30:53 From submit: Submitting job(s).
10/24/16 16:30:53 From submit: 1 job(s) submitted to cluster 407.
10/24/16 16:30:53 	assigned Condor ID (407.0.0)
10/24/16 16:30:53 Submitting Condor Node mediancpu_0_ID0000004 job(s)...
10/24/16 16:30:53 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:30:53 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:30:53 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:30:53 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'mediancpu_0_ID0000004 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'mediancpu_0_ID0000004 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_2_0,stage_in_remote_local_2_0,generalinfo_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/mediancpu_0_ID0000004.sub
10/24/16 16:30:53 From submit: Submitting job(s).
10/24/16 16:30:53 From submit: 1 job(s) submitted to cluster 408.
10/24/16 16:30:53 	assigned Condor ID (408.0.0)
10/24/16 16:30:53 Just submitted 4 jobs this cycle...
10/24/16 16:30:53 Currently monitoring 1 Condor log file(s)
10/24/16 16:30:53 Reassigning the id of job clean_up_local_level_4_0 from (405.0.0) to (405.0.0)
10/24/16 16:30:53 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_4_0 (405.0.0)
10/24/16 16:30:53 Number of idle job procs: 1
10/24/16 16:30:53 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_4_0 (405.0.0)
10/24/16 16:30:53 Number of idle job procs: 0
10/24/16 16:30:53 Reassigning the id of job statscpumemory_0_ID0000003 from (406.0.0) to (406.0.0)
10/24/16 16:30:53 Event: ULOG_SUBMIT for Condor Node statscpumemory_0_ID0000003 (406.0.0)
10/24/16 16:30:53 Number of idle job procs: 1
10/24/16 16:30:53 Reassigning the id of job medianmemory_0_ID0000005 from (407.0.0) to (407.0.0)
10/24/16 16:30:53 Event: ULOG_SUBMIT for Condor Node medianmemory_0_ID0000005 (407.0.0)
10/24/16 16:30:53 Number of idle job procs: 2
10/24/16 16:30:53 Reassigning the id of job mediancpu_0_ID0000004 from (408.0.0) to (408.0.0)
10/24/16 16:30:53 Event: ULOG_SUBMIT for Condor Node mediancpu_0_ID0000004 (408.0.0)
10/24/16 16:30:53 Number of idle job procs: 3
10/24/16 16:30:53 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:30:53 Of 39 nodes total:
10/24/16 16:30:53  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:30:53   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:30:53    22       0        4       0       0         13        0
10/24/16 16:30:53 0 job proc(s) currently held
10/24/16 16:30:58 Currently monitoring 1 Condor log file(s)
10/24/16 16:30:58 Event: ULOG_EXECUTE for Condor Node statscpumemory_0_ID0000003 (406.0.0)
10/24/16 16:30:58 Number of idle job procs: 2
10/24/16 16:30:58 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_4_0 (405.0.0)
10/24/16 16:30:58 Number of idle job procs: 2
10/24/16 16:30:58 Node clean_up_local_level_4_0 job proc (405.0.0) completed successfully.
10/24/16 16:30:58 Node clean_up_local_level_4_0 job completed
10/24/16 16:30:58 Running POST script of Node clean_up_local_level_4_0...
10/24/16 16:30:58 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:30:58 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:30:58 Of 39 nodes total:
10/24/16 16:30:58  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:30:58   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:30:58    22       0        3       1       0         13        0
10/24/16 16:30:58 0 job proc(s) currently held
10/24/16 16:30:58 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (405.0.0)
10/24/16 16:31:03 Currently monitoring 1 Condor log file(s)
10/24/16 16:31:03 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_4_0 (405.0.0)
10/24/16 16:31:03 POST Script of Node clean_up_local_level_4_0 completed successfully.
10/24/16 16:31:03 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:31:03 Of 39 nodes total:
10/24/16 16:31:03  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:31:03   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:31:03    23       0        3       0       0         13        0
10/24/16 16:31:03 0 job proc(s) currently held
10/24/16 16:39:39 Currently monitoring 1 Condor log file(s)
10/24/16 16:39:39 Event: ULOG_JOB_TERMINATED for Condor Node statscpumemory_0_ID0000003 (406.0.0)
10/24/16 16:39:39 Number of idle job procs: 2
10/24/16 16:39:39 Node statscpumemory_0_ID0000003 job proc (406.0.0) completed successfully.
10/24/16 16:39:39 Node statscpumemory_0_ID0000003 job completed
10/24/16 16:39:39 Running POST script of Node statscpumemory_0_ID0000003...
10/24/16 16:39:39 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:39:39 Event: ULOG_EXECUTE for Condor Node medianmemory_0_ID0000005 (407.0.0)
10/24/16 16:39:39 Number of idle job procs: 1
10/24/16 16:39:39 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:39:39 Of 39 nodes total:
10/24/16 16:39:39  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:39:39   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:39:39    23       0        2       1       0         13        0
10/24/16 16:39:39 0 job proc(s) currently held
10/24/16 16:39:39 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (406.0.0)
10/24/16 16:39:44 Currently monitoring 1 Condor log file(s)
10/24/16 16:39:44 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node statscpumemory_0_ID0000003 (406.0.0)
10/24/16 16:39:44 POST Script of Node statscpumemory_0_ID0000003 completed successfully.
10/24/16 16:39:44 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:39:44 Of 39 nodes total:
10/24/16 16:39:44  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:39:44   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:39:44    24       0        2       0       0         13        0
10/24/16 16:39:44 0 job proc(s) currently held
10/24/16 16:48:19 Currently monitoring 1 Condor log file(s)
10/24/16 16:48:19 Event: ULOG_JOB_TERMINATED for Condor Node medianmemory_0_ID0000005 (407.0.0)
10/24/16 16:48:19 Number of idle job procs: 1
10/24/16 16:48:19 Node medianmemory_0_ID0000005 job proc (407.0.0) completed successfully.
10/24/16 16:48:19 Node medianmemory_0_ID0000005 job completed
10/24/16 16:48:19 Running POST script of Node medianmemory_0_ID0000005...
10/24/16 16:48:19 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:48:19 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:48:19 Of 39 nodes total:
10/24/16 16:48:19  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:48:19   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:48:19    24       0        1       1       0         13        0
10/24/16 16:48:19 0 job proc(s) currently held
10/24/16 16:48:20 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (407.0.0)
10/24/16 16:48:24 Currently monitoring 1 Condor log file(s)
10/24/16 16:48:24 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node medianmemory_0_ID0000005 (407.0.0)
10/24/16 16:48:24 POST Script of Node medianmemory_0_ID0000005 completed successfully.
10/24/16 16:48:24 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:48:24 Of 39 nodes total:
10/24/16 16:48:24  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:48:24   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:48:24    25       0        1       0       1         12        0
10/24/16 16:48:24 0 job proc(s) currently held
10/24/16 16:48:29 Submitting Condor Node clean_up_local_level_5_0 job(s)...
10/24/16 16:48:29 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:48:29 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:48:29 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:48:29 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_5_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_5_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"statscpumemory_0_ID0000003,medianmemory_0_ID0000005" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_5_0.sub
10/24/16 16:48:29 From submit: Submitting job(s).
10/24/16 16:48:29 From submit: 1 job(s) submitted to cluster 409.
10/24/16 16:48:29 	assigned Condor ID (409.0.0)
10/24/16 16:48:29 Just submitted 1 job this cycle...
10/24/16 16:48:29 Currently monitoring 1 Condor log file(s)
10/24/16 16:48:29 Reassigning the id of job clean_up_local_level_5_0 from (409.0.0) to (409.0.0)
10/24/16 16:48:29 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_5_0 (409.0.0)
10/24/16 16:48:29 Number of idle job procs: 2
10/24/16 16:48:29 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:48:29 Of 39 nodes total:
10/24/16 16:48:29  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:48:29   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:48:29    25       0        2       0       0         12        0
10/24/16 16:48:29 0 job proc(s) currently held
10/24/16 16:48:34 Currently monitoring 1 Condor log file(s)
10/24/16 16:48:34 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_5_0 (409.0.0)
10/24/16 16:48:34 Number of idle job procs: 1
10/24/16 16:48:34 Event: ULOG_EXECUTE for Condor Node mediancpu_0_ID0000004 (408.0.0)
10/24/16 16:48:34 Number of idle job procs: 0
10/24/16 16:48:39 Currently monitoring 1 Condor log file(s)
10/24/16 16:48:39 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_5_0 (409.0.0)
10/24/16 16:48:39 Number of idle job procs: 0
10/24/16 16:48:39 Node clean_up_local_level_5_0 job proc (409.0.0) completed successfully.
10/24/16 16:48:39 Node clean_up_local_level_5_0 job completed
10/24/16 16:48:39 Running POST script of Node clean_up_local_level_5_0...
10/24/16 16:48:39 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:48:39 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:48:39 Of 39 nodes total:
10/24/16 16:48:39  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:48:39   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:48:39    25       0        1       1       0         12        0
10/24/16 16:48:39 0 job proc(s) currently held
10/24/16 16:48:39 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (409.0.0)
10/24/16 16:48:44 Currently monitoring 1 Condor log file(s)
10/24/16 16:48:44 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_5_0 (409.0.0)
10/24/16 16:48:44 POST Script of Node clean_up_local_level_5_0 completed successfully.
10/24/16 16:48:44 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:48:44 Of 39 nodes total:
10/24/16 16:48:44  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:48:44   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:48:44    26       0        1       0       0         12        0
10/24/16 16:48:44 0 job proc(s) currently held
10/24/16 16:57:30 Currently monitoring 1 Condor log file(s)
10/24/16 16:57:30 Event: ULOG_JOB_TERMINATED for Condor Node mediancpu_0_ID0000004 (408.0.0)
10/24/16 16:57:30 Number of idle job procs: 0
10/24/16 16:57:30 Node mediancpu_0_ID0000004 job proc (408.0.0) completed successfully.
10/24/16 16:57:30 Node mediancpu_0_ID0000004 job completed
10/24/16 16:57:30 Running POST script of Node mediancpu_0_ID0000004...
10/24/16 16:57:30 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:57:30 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:57:30 Of 39 nodes total:
10/24/16 16:57:30  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:57:30   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:57:30    26       0        0       1       0         12        0
10/24/16 16:57:30 0 job proc(s) currently held
10/24/16 16:57:30 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (408.0.0)
10/24/16 16:57:35 Currently monitoring 1 Condor log file(s)
10/24/16 16:57:35 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node mediancpu_0_ID0000004 (408.0.0)
10/24/16 16:57:35 POST Script of Node mediancpu_0_ID0000004 completed successfully.
10/24/16 16:57:35 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:57:35 Of 39 nodes total:
10/24/16 16:57:35  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:57:35   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:57:35    27       0        0       0       2         10        0
10/24/16 16:57:35 0 job proc(s) currently held
10/24/16 16:57:40 Submitting Condor Node taskevent_0_ID0000006 job(s)...
10/24/16 16:57:40 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:57:40 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:57:40 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:57:40 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'taskevent_0_ID0000006 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'taskevent_0_ID0000006 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_3_0,stage_in_remote_local_3_1,stage_in_remote_local_3_0,statscpumemory_0_ID0000003,medianmemory_0_ID0000005,mediancpu_0_ID0000004" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/taskevent_0_ID0000006.sub
10/24/16 16:57:40 From submit: Submitting job(s).
10/24/16 16:57:40 From submit: 1 job(s) submitted to cluster 410.
10/24/16 16:57:40 	assigned Condor ID (410.0.0)
10/24/16 16:57:40 Submitting Condor Node clean_up_local_level_5_1 job(s)...
10/24/16 16:57:40 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 16:57:40 Masking the events recorded in the DAGMAN workflow log
10/24/16 16:57:40 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 16:57:40 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_5_1 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_5_1 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"mediancpu_0_ID0000004" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_5_1.sub
10/24/16 16:57:40 From submit: Submitting job(s).
10/24/16 16:57:40 From submit: 1 job(s) submitted to cluster 411.
10/24/16 16:57:40 	assigned Condor ID (411.0.0)
10/24/16 16:57:40 Just submitted 2 jobs this cycle...
10/24/16 16:57:40 Currently monitoring 1 Condor log file(s)
10/24/16 16:57:40 Reassigning the id of job taskevent_0_ID0000006 from (410.0.0) to (410.0.0)
10/24/16 16:57:40 Event: ULOG_SUBMIT for Condor Node taskevent_0_ID0000006 (410.0.0)
10/24/16 16:57:40 Number of idle job procs: 1
10/24/16 16:57:40 Reassigning the id of job clean_up_local_level_5_1 from (411.0.0) to (411.0.0)
10/24/16 16:57:40 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_5_1 (411.0.0)
10/24/16 16:57:40 Number of idle job procs: 2
10/24/16 16:57:40 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:57:40 Of 39 nodes total:
10/24/16 16:57:40  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:57:40   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:57:40    27       0        2       0       0         10        0
10/24/16 16:57:40 0 job proc(s) currently held
10/24/16 16:57:45 Currently monitoring 1 Condor log file(s)
10/24/16 16:57:45 Event: ULOG_EXECUTE for Condor Node taskevent_0_ID0000006 (410.0.0)
10/24/16 16:57:45 Number of idle job procs: 1
10/24/16 16:57:45 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_5_1 (411.0.0)
10/24/16 16:57:45 Number of idle job procs: 0
10/24/16 16:57:50 Currently monitoring 1 Condor log file(s)
10/24/16 16:57:50 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_5_1 (411.0.0)
10/24/16 16:57:50 Number of idle job procs: 0
10/24/16 16:57:50 Node clean_up_local_level_5_1 job proc (411.0.0) completed successfully.
10/24/16 16:57:50 Node clean_up_local_level_5_1 job completed
10/24/16 16:57:50 Running POST script of Node clean_up_local_level_5_1...
10/24/16 16:57:50 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 16:57:50 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:57:50 Of 39 nodes total:
10/24/16 16:57:50  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:57:50   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:57:50    27       0        1       1       0         10        0
10/24/16 16:57:50 0 job proc(s) currently held
10/24/16 16:57:50 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (411.0.0)
10/24/16 16:57:55 Currently monitoring 1 Condor log file(s)
10/24/16 16:57:55 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_5_1 (411.0.0)
10/24/16 16:57:55 POST Script of Node clean_up_local_level_5_1 completed successfully.
10/24/16 16:57:55 DAG status: 0 (DAG_STATUS_OK)
10/24/16 16:57:55 Of 39 nodes total:
10/24/16 16:57:55  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 16:57:55   ===     ===      ===     ===     ===        ===      ===
10/24/16 16:57:55    28       0        1       0       0         10        0
10/24/16 16:57:55 0 job proc(s) currently held
10/24/16 17:07:56 601 seconds since last log event
10/24/16 17:07:56 Pending DAG nodes:
10/24/16 17:07:56   Node taskevent_0_ID0000006, Condor ID 410, status STATUS_SUBMITTED
10/24/16 17:13:16 Currently monitoring 1 Condor log file(s)
10/24/16 17:13:16 Event: ULOG_JOB_TERMINATED for Condor Node taskevent_0_ID0000006 (410.0.0)
10/24/16 17:13:16 Number of idle job procs: 0
10/24/16 17:13:16 Node taskevent_0_ID0000006 job proc (410.0.0) completed successfully.
10/24/16 17:13:16 Node taskevent_0_ID0000006 job completed
10/24/16 17:13:16 Running POST script of Node taskevent_0_ID0000006...
10/24/16 17:13:16 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:13:16 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:13:16 Of 39 nodes total:
10/24/16 17:13:16  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:13:16   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:13:16    28       0        0       1       0         10        0
10/24/16 17:13:16 0 job proc(s) currently held
10/24/16 17:13:16 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (410.0.0)
10/24/16 17:13:21 Currently monitoring 1 Condor log file(s)
10/24/16 17:13:21 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node taskevent_0_ID0000006 (410.0.0)
10/24/16 17:13:21 POST Script of Node taskevent_0_ID0000006 completed successfully.
10/24/16 17:13:21 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:13:21 Of 39 nodes total:
10/24/16 17:13:21  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:13:21   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:13:21    29       0        0       0       2          8        0
10/24/16 17:13:21 0 job proc(s) currently held
10/24/16 17:13:26 Submitting Condor Node clean_up_local_level_6_0 job(s)...
10/24/16 17:13:26 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:13:26 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:13:26 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:13:26 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_6_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_6_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"taskevent_0_ID0000006" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_6_0.sub
10/24/16 17:13:26 From submit: Submitting job(s).
10/24/16 17:13:26 From submit: 1 job(s) submitted to cluster 412.
10/24/16 17:13:26 	assigned Condor ID (412.0.0)
10/24/16 17:13:26 Submitting Condor Node calculateratio_0_ID0000007 job(s)...
10/24/16 17:13:26 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:13:26 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:13:26 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:13:26 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'calculateratio_0_ID0000007 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'calculateratio_0_ID0000007 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_4_0,stage_in_remote_local_4_1,stage_in_remote_local_4_0,taskevent_0_ID0000006" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/calculateratio_0_ID0000007.sub
10/24/16 17:13:26 From submit: Submitting job(s).
10/24/16 17:13:26 From submit: 1 job(s) submitted to cluster 413.
10/24/16 17:13:26 	assigned Condor ID (413.0.0)
10/24/16 17:13:26 Just submitted 2 jobs this cycle...
10/24/16 17:13:26 Currently monitoring 1 Condor log file(s)
10/24/16 17:13:26 Reassigning the id of job clean_up_local_level_6_0 from (412.0.0) to (412.0.0)
10/24/16 17:13:26 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_6_0 (412.0.0)
10/24/16 17:13:26 Number of idle job procs: 1
10/24/16 17:13:26 Reassigning the id of job calculateratio_0_ID0000007 from (413.0.0) to (413.0.0)
10/24/16 17:13:26 Event: ULOG_SUBMIT for Condor Node calculateratio_0_ID0000007 (413.0.0)
10/24/16 17:13:26 Number of idle job procs: 2
10/24/16 17:13:26 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_6_0 (412.0.0)
10/24/16 17:13:26 Number of idle job procs: 1
10/24/16 17:13:26 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:13:26 Of 39 nodes total:
10/24/16 17:13:26  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:13:26   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:13:26    29       0        2       0       0          8        0
10/24/16 17:13:26 0 job proc(s) currently held
10/24/16 17:13:36 Currently monitoring 1 Condor log file(s)
10/24/16 17:13:36 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_6_0 (412.0.0)
10/24/16 17:13:36 Number of idle job procs: 1
10/24/16 17:13:36 Node clean_up_local_level_6_0 job proc (412.0.0) completed successfully.
10/24/16 17:13:36 Node clean_up_local_level_6_0 job completed
10/24/16 17:13:36 Running POST script of Node clean_up_local_level_6_0...
10/24/16 17:13:36 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:13:36 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:13:36 Of 39 nodes total:
10/24/16 17:13:36  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:13:36   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:13:36    29       0        1       1       0          8        0
10/24/16 17:13:36 0 job proc(s) currently held
10/24/16 17:13:37 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (412.0.0)
10/24/16 17:13:41 Currently monitoring 1 Condor log file(s)
10/24/16 17:13:41 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_6_0 (412.0.0)
10/24/16 17:13:41 POST Script of Node clean_up_local_level_6_0 completed successfully.
10/24/16 17:13:41 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:13:41 Of 39 nodes total:
10/24/16 17:13:41  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:13:41   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:13:41    30       0        1       0       0          8        0
10/24/16 17:13:41 0 job proc(s) currently held
10/24/16 17:13:51 Currently monitoring 1 Condor log file(s)
10/24/16 17:13:51 Event: ULOG_EXECUTE for Condor Node calculateratio_0_ID0000007 (413.0.0)
10/24/16 17:13:51 Number of idle job procs: 0
10/24/16 17:23:51 600 seconds since last log event
10/24/16 17:23:51 Pending DAG nodes:
10/24/16 17:23:51   Node calculateratio_0_ID0000007, Condor ID 413, status STATUS_SUBMITTED
10/24/16 17:28:11 Currently monitoring 1 Condor log file(s)
10/24/16 17:28:11 Event: ULOG_JOB_TERMINATED for Condor Node calculateratio_0_ID0000007 (413.0.0)
10/24/16 17:28:11 Number of idle job procs: 0
10/24/16 17:28:11 Node calculateratio_0_ID0000007 job proc (413.0.0) completed successfully.
10/24/16 17:28:11 Node calculateratio_0_ID0000007 job completed
10/24/16 17:28:11 Running POST script of Node calculateratio_0_ID0000007...
10/24/16 17:28:11 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:28:11 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:28:11 Of 39 nodes total:
10/24/16 17:28:11  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:28:11   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:28:11    30       0        0       1       0          8        0
10/24/16 17:28:11 0 job proc(s) currently held
10/24/16 17:28:12 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (413.0.0)
10/24/16 17:28:16 Currently monitoring 1 Condor log file(s)
10/24/16 17:28:16 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node calculateratio_0_ID0000007 (413.0.0)
10/24/16 17:28:16 POST Script of Node calculateratio_0_ID0000007 completed successfully.
10/24/16 17:28:16 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:28:16 Of 39 nodes total:
10/24/16 17:28:16  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:28:16   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:28:16    31       0        0       0       2          6        0
10/24/16 17:28:16 0 job proc(s) currently held
10/24/16 17:28:21 Submitting Condor Node clean_up_local_level_7_0 job(s)...
10/24/16 17:28:21 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:28:21 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:28:21 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:28:21 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_7_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_7_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"calculateratio_0_ID0000007" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_7_0.sub
10/24/16 17:28:21 From submit: Submitting job(s).
10/24/16 17:28:21 From submit: 1 job(s) submitted to cluster 414.
10/24/16 17:28:21 	assigned Condor ID (414.0.0)
10/24/16 17:28:21 Submitting Condor Node averageratioevent_0_ID0000008 job(s)...
10/24/16 17:28:21 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:28:21 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:28:21 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:28:21 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'averageratioevent_0_ID0000008 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'averageratioevent_0_ID0000008 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_remote_local_5_0,stage_in_local_local_5_0,calculateratio_0_ID0000007" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/averageratioevent_0_ID0000008.sub
10/24/16 17:28:21 From submit: Submitting job(s).
10/24/16 17:28:21 From submit: 1 job(s) submitted to cluster 415.
10/24/16 17:28:21 	assigned Condor ID (415.0.0)
10/24/16 17:28:21 Just submitted 2 jobs this cycle...
10/24/16 17:28:21 Currently monitoring 1 Condor log file(s)
10/24/16 17:28:21 Reassigning the id of job clean_up_local_level_7_0 from (414.0.0) to (414.0.0)
10/24/16 17:28:21 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_7_0 (414.0.0)
10/24/16 17:28:21 Number of idle job procs: 1
10/24/16 17:28:21 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_7_0 (414.0.0)
10/24/16 17:28:21 Number of idle job procs: 0
10/24/16 17:28:21 Reassigning the id of job averageratioevent_0_ID0000008 from (415.0.0) to (415.0.0)
10/24/16 17:28:21 Event: ULOG_SUBMIT for Condor Node averageratioevent_0_ID0000008 (415.0.0)
10/24/16 17:28:21 Number of idle job procs: 1
10/24/16 17:28:21 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:28:21 Of 39 nodes total:
10/24/16 17:28:21  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:28:21   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:28:21    31       0        2       0       0          6        0
10/24/16 17:28:21 0 job proc(s) currently held
10/24/16 17:28:26 Currently monitoring 1 Condor log file(s)
10/24/16 17:28:26 Event: ULOG_EXECUTE for Condor Node averageratioevent_0_ID0000008 (415.0.0)
10/24/16 17:28:26 Number of idle job procs: 0
10/24/16 17:28:31 Currently monitoring 1 Condor log file(s)
10/24/16 17:28:31 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_7_0 (414.0.0)
10/24/16 17:28:31 Number of idle job procs: 0
10/24/16 17:28:31 Node clean_up_local_level_7_0 job proc (414.0.0) completed successfully.
10/24/16 17:28:31 Node clean_up_local_level_7_0 job completed
10/24/16 17:28:31 Running POST script of Node clean_up_local_level_7_0...
10/24/16 17:28:31 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:28:31 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:28:31 Of 39 nodes total:
10/24/16 17:28:31  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:28:31   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:28:31    31       0        1       1       0          6        0
10/24/16 17:28:31 0 job proc(s) currently held
10/24/16 17:28:31 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (414.0.0)
10/24/16 17:28:36 Currently monitoring 1 Condor log file(s)
10/24/16 17:28:36 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_7_0 (414.0.0)
10/24/16 17:28:36 POST Script of Node clean_up_local_level_7_0 completed successfully.
10/24/16 17:28:36 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:28:36 Of 39 nodes total:
10/24/16 17:28:36  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:28:36   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:28:36    32       0        1       0       0          6        0
10/24/16 17:28:36 0 job proc(s) currently held
10/24/16 17:29:31 Currently monitoring 1 Condor log file(s)
10/24/16 17:29:31 Event: ULOG_JOB_TERMINATED for Condor Node averageratioevent_0_ID0000008 (415.0.0)
10/24/16 17:29:31 Number of idle job procs: 0
10/24/16 17:29:31 Node averageratioevent_0_ID0000008 job proc (415.0.0) completed successfully.
10/24/16 17:29:31 Node averageratioevent_0_ID0000008 job completed
10/24/16 17:29:31 Running POST script of Node averageratioevent_0_ID0000008...
10/24/16 17:29:31 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:29:31 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:29:31 Of 39 nodes total:
10/24/16 17:29:31  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:29:31   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:29:31    32       0        0       1       0          6        0
10/24/16 17:29:31 0 job proc(s) currently held
10/24/16 17:29:31 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (415.0.0)
10/24/16 17:29:36 Currently monitoring 1 Condor log file(s)
10/24/16 17:29:36 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node averageratioevent_0_ID0000008 (415.0.0)
10/24/16 17:29:36 POST Script of Node averageratioevent_0_ID0000008 completed successfully.
10/24/16 17:29:36 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:29:36 Of 39 nodes total:
10/24/16 17:29:36  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:29:36   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:29:36    33       0        0       0       2          4        0
10/24/16 17:29:36 0 job proc(s) currently held
10/24/16 17:29:41 Submitting Condor Node clean_up_local_level_8_0 job(s)...
10/24/16 17:29:41 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:29:41 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:29:41 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:29:41 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_8_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_8_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"averageratioevent_0_ID0000008" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_8_0.sub
10/24/16 17:29:41 From submit: Submitting job(s).
10/24/16 17:29:41 From submit: 1 job(s) submitted to cluster 416.
10/24/16 17:29:41 	assigned Condor ID (416.0.0)
10/24/16 17:29:41 Submitting Condor Node analysisevent_0_ID0000009 job(s)...
10/24/16 17:29:41 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:29:41 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:29:41 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:29:41 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'analysisevent_0_ID0000009 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'analysisevent_0_ID0000009 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_6_0,stage_in_remote_local_6_0,averageratioevent_0_ID0000008" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/analysisevent_0_ID0000009.sub
10/24/16 17:29:41 From submit: Submitting job(s).
10/24/16 17:29:41 From submit: 1 job(s) submitted to cluster 417.
10/24/16 17:29:41 	assigned Condor ID (417.0.0)
10/24/16 17:29:41 Just submitted 2 jobs this cycle...
10/24/16 17:29:41 Currently monitoring 1 Condor log file(s)
10/24/16 17:29:41 Reassigning the id of job clean_up_local_level_8_0 from (416.0.0) to (416.0.0)
10/24/16 17:29:41 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_8_0 (416.0.0)
10/24/16 17:29:41 Number of idle job procs: 1
10/24/16 17:29:41 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_8_0 (416.0.0)
10/24/16 17:29:41 Number of idle job procs: 0
10/24/16 17:29:41 Reassigning the id of job analysisevent_0_ID0000009 from (417.0.0) to (417.0.0)
10/24/16 17:29:41 Event: ULOG_SUBMIT for Condor Node analysisevent_0_ID0000009 (417.0.0)
10/24/16 17:29:41 Number of idle job procs: 1
10/24/16 17:29:41 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:29:41 Of 39 nodes total:
10/24/16 17:29:41  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:29:41   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:29:41    33       0        2       0       0          4        0
10/24/16 17:29:41 0 job proc(s) currently held
10/24/16 17:29:47 Currently monitoring 1 Condor log file(s)
10/24/16 17:29:47 Event: ULOG_EXECUTE for Condor Node analysisevent_0_ID0000009 (417.0.0)
10/24/16 17:29:47 Number of idle job procs: 0
10/24/16 17:29:47 Event: ULOG_JOB_TERMINATED for Condor Node analysisevent_0_ID0000009 (417.0.0)
10/24/16 17:29:47 Number of idle job procs: 0
10/24/16 17:29:47 Node analysisevent_0_ID0000009 job proc (417.0.0) completed successfully.
10/24/16 17:29:47 Node analysisevent_0_ID0000009 job completed
10/24/16 17:29:47 Running POST script of Node analysisevent_0_ID0000009...
10/24/16 17:29:47 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:29:47 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_8_0 (416.0.0)
10/24/16 17:29:47 Number of idle job procs: 0
10/24/16 17:29:47 Node clean_up_local_level_8_0 job proc (416.0.0) completed successfully.
10/24/16 17:29:47 Node clean_up_local_level_8_0 job completed
10/24/16 17:29:47 Running POST script of Node clean_up_local_level_8_0...
10/24/16 17:29:47 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:29:47 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:29:47 Of 39 nodes total:
10/24/16 17:29:47  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:29:47   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:29:47    33       0        0       2       0          4        0
10/24/16 17:29:47 0 job proc(s) currently held
10/24/16 17:29:47 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (417.0.0)
10/24/16 17:29:47 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (416.0.0)
10/24/16 17:29:52 Currently monitoring 1 Condor log file(s)
10/24/16 17:29:52 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node analysisevent_0_ID0000009 (417.0.0)
10/24/16 17:29:52 POST Script of Node analysisevent_0_ID0000009 completed successfully.
10/24/16 17:29:52 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_8_0 (416.0.0)
10/24/16 17:29:52 POST Script of Node clean_up_local_level_8_0 completed successfully.
10/24/16 17:29:52 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:29:52 Of 39 nodes total:
10/24/16 17:29:52  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:29:52   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:29:52    35       0        0       0       2          2        0
10/24/16 17:29:52 0 job proc(s) currently held
10/24/16 17:29:57 Submitting Condor Node terminate_0_ID0000010 job(s)...
10/24/16 17:29:57 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:29:57 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:29:57 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:29:57 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'terminate_0_ID0000010 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'terminate_0_ID0000010 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_7_0,analysisevent_0_ID0000009" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/terminate_0_ID0000010.sub
10/24/16 17:29:57 From submit: Submitting job(s).
10/24/16 17:29:57 From submit: 1 job(s) submitted to cluster 418.
10/24/16 17:29:57 	assigned Condor ID (418.0.0)
10/24/16 17:29:57 Submitting Condor Node clean_up_local_level_9_0 job(s)...
10/24/16 17:29:57 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:29:57 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:29:57 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:29:57 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_9_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_9_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"analysisevent_0_ID0000009" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_9_0.sub
10/24/16 17:29:57 From submit: Submitting job(s).
10/24/16 17:29:57 From submit: 1 job(s) submitted to cluster 419.
10/24/16 17:29:57 	assigned Condor ID (419.0.0)
10/24/16 17:29:57 Just submitted 2 jobs this cycle...
10/24/16 17:29:57 Currently monitoring 1 Condor log file(s)
10/24/16 17:29:57 Reassigning the id of job terminate_0_ID0000010 from (418.0.0) to (418.0.0)
10/24/16 17:29:57 Event: ULOG_SUBMIT for Condor Node terminate_0_ID0000010 (418.0.0)
10/24/16 17:29:57 Number of idle job procs: 1
10/24/16 17:29:57 Reassigning the id of job clean_up_local_level_9_0 from (419.0.0) to (419.0.0)
10/24/16 17:29:57 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_9_0 (419.0.0)
10/24/16 17:29:57 Number of idle job procs: 2
10/24/16 17:29:57 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:29:57 Of 39 nodes total:
10/24/16 17:29:57  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:29:57   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:29:57    35       0        2       0       0          2        0
10/24/16 17:29:57 0 job proc(s) currently held
10/24/16 17:30:02 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:02 Event: ULOG_EXECUTE for Condor Node terminate_0_ID0000010 (418.0.0)
10/24/16 17:30:02 Number of idle job procs: 1
10/24/16 17:30:02 Event: ULOG_JOB_TERMINATED for Condor Node terminate_0_ID0000010 (418.0.0)
10/24/16 17:30:02 Number of idle job procs: 1
10/24/16 17:30:02 Node terminate_0_ID0000010 job proc (418.0.0) completed successfully.
10/24/16 17:30:02 Node terminate_0_ID0000010 job completed
10/24/16 17:30:02 Running POST script of Node terminate_0_ID0000010...
10/24/16 17:30:02 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:30:02 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:02 Of 39 nodes total:
10/24/16 17:30:02  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:02   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:02    35       0        1       1       0          2        0
10/24/16 17:30:02 0 job proc(s) currently held
10/24/16 17:30:02 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (418.0.0)
10/24/16 17:30:07 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:07 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_9_0 (419.0.0)
10/24/16 17:30:07 Number of idle job procs: 0
10/24/16 17:30:07 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node terminate_0_ID0000010 (418.0.0)
10/24/16 17:30:07 POST Script of Node terminate_0_ID0000010 completed successfully.
10/24/16 17:30:07 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_9_0 (419.0.0)
10/24/16 17:30:07 Number of idle job procs: 0
10/24/16 17:30:07 Node clean_up_local_level_9_0 job proc (419.0.0) completed successfully.
10/24/16 17:30:07 Node clean_up_local_level_9_0 job completed
10/24/16 17:30:07 Running POST script of Node clean_up_local_level_9_0...
10/24/16 17:30:07 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:30:07 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:07 Of 39 nodes total:
10/24/16 17:30:07  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:07   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:07    36       0        0       1       1          1        0
10/24/16 17:30:07 0 job proc(s) currently held
10/24/16 17:30:07 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (419.0.0)
10/24/16 17:30:12 Submitting Condor Node clean_up_local_level_10_0 job(s)...
10/24/16 17:30:12 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:30:12 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:30:12 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:30:12 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_10_0 -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_10_0 -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"terminate_0_ID0000010" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_10_0.sub
10/24/16 17:30:12 From submit: Submitting job(s).
10/24/16 17:30:12 From submit: 1 job(s) submitted to cluster 420.
10/24/16 17:30:12 	assigned Condor ID (420.0.0)
10/24/16 17:30:12 Just submitted 1 job this cycle...
10/24/16 17:30:12 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:12 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_9_0 (419.0.0)
10/24/16 17:30:12 POST Script of Node clean_up_local_level_9_0 completed successfully.
10/24/16 17:30:12 Reassigning the id of job clean_up_local_level_10_0 from (420.0.0) to (420.0.0)
10/24/16 17:30:12 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_10_0 (420.0.0)
10/24/16 17:30:12 Number of idle job procs: 1
10/24/16 17:30:12 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:12 Of 39 nodes total:
10/24/16 17:30:12  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:12   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:12    37       0        1       0       0          1        0
10/24/16 17:30:12 0 job proc(s) currently held
10/24/16 17:30:17 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:17 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_10_0 (420.0.0)
10/24/16 17:30:17 Number of idle job procs: 0
10/24/16 17:30:17 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_10_0 (420.0.0)
10/24/16 17:30:17 Number of idle job procs: 0
10/24/16 17:30:17 Node clean_up_local_level_10_0 job proc (420.0.0) completed successfully.
10/24/16 17:30:17 Node clean_up_local_level_10_0 job completed
10/24/16 17:30:17 Running POST script of Node clean_up_local_level_10_0...
10/24/16 17:30:17 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:30:17 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:17 Of 39 nodes total:
10/24/16 17:30:17  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:17   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:17    37       0        0       1       0          1        0
10/24/16 17:30:17 0 job proc(s) currently held
10/24/16 17:30:18 Initializing user log writer for /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log, (420.0.0)
10/24/16 17:30:22 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:22 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_10_0 (420.0.0)
10/24/16 17:30:22 POST Script of Node clean_up_local_level_10_0 completed successfully.
10/24/16 17:30:22 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:22 Of 39 nodes total:
10/24/16 17:30:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:22   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:22    38       0        0       0       1          0        0
10/24/16 17:30:22 0 job proc(s) currently held
10/24/16 17:30:27 Submitting Condor Node cleanup_example_workflow_0_local job(s)...
10/24/16 17:30:27 Adding a DAGMan workflow log /home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log
10/24/16 17:30:27 Masking the events recorded in the DAGMAN workflow log
10/24/16 17:30:27 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
10/24/16 17:30:27 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'cleanup_example_workflow_0_local -a +DAGManJobId' '=' '382 -a DAGManJobId' '=' '382 -a submit_event_notes' '=' 'DAG' 'Node:' 'cleanup_example_workflow_0_local -a dagman_log' '=' '/home/ubuntu/0_experiments/2-mongodb-1sh-1rp-small/4_workflow_full_10files_primary_1sh_1rs_noannot_with_proj_1s/dags/ubuntu/pegasus/example_workflow/20161024T162426+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"clean_up_local_level_3_0,clean_up_local_level_4_0,clean_up_local_level_5_0,clean_up_local_level_5_1,clean_up_local_level_6_0,clean_up_local_level_7_0,clean_up_local_level_8_0,clean_up_local_level_9_0,clean_up_local_level_10_0" -a notification' '=' 'never 00/00/cleanup_example_workflow_0_local.sub
10/24/16 17:30:27 From submit: Submitting job(s).
10/24/16 17:30:27 From submit: 1 job(s) submitted to cluster 421.
10/24/16 17:30:27 	assigned Condor ID (421.0.0)
10/24/16 17:30:27 Just submitted 1 job this cycle...
10/24/16 17:30:27 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:27 Reassigning the id of job cleanup_example_workflow_0_local from (421.0.0) to (421.0.0)
10/24/16 17:30:27 Event: ULOG_SUBMIT for Condor Node cleanup_example_workflow_0_local (421.0.0)
10/24/16 17:30:27 Number of idle job procs: 1
10/24/16 17:30:27 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:27 Of 39 nodes total:
10/24/16 17:30:27  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:27   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:27    38       0        1       0       0          0        0
10/24/16 17:30:27 0 job proc(s) currently held
10/24/16 17:30:32 Currently monitoring 1 Condor log file(s)
10/24/16 17:30:32 Event: ULOG_EXECUTE for Condor Node cleanup_example_workflow_0_local (421.0.0)
10/24/16 17:30:32 Number of idle job procs: 0
10/24/16 17:30:32 Event: ULOG_JOB_TERMINATED for Condor Node cleanup_example_workflow_0_local (421.0.0)
10/24/16 17:30:32 Number of idle job procs: 0
10/24/16 17:30:32 Node cleanup_example_workflow_0_local job proc (421.0.0) completed successfully.
10/24/16 17:30:32 Node cleanup_example_workflow_0_local job completed
10/24/16 17:30:32 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:32 Of 39 nodes total:
10/24/16 17:30:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:32   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:32    39       0        0       0       0          0        0
10/24/16 17:30:32 0 job proc(s) currently held
10/24/16 17:30:32 All jobs Completed!
10/24/16 17:30:32 Note: 0 total job deferrals because of -MaxJobs limit (0)
10/24/16 17:30:32 Note: 0 total job deferrals because of -MaxIdle limit (1000)
10/24/16 17:30:32 Note: 0 total job deferrals because of node category throttles
10/24/16 17:30:32 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
10/24/16 17:30:32 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
10/24/16 17:30:32 DAG status: 0 (DAG_STATUS_OK)
10/24/16 17:30:32 Of 39 nodes total:
10/24/16 17:30:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
10/24/16 17:30:32   ===     ===      ===     ===     ===        ===      ===
10/24/16 17:30:32    39       0        0       0       0          0        0
10/24/16 17:30:32 0 job proc(s) currently held
10/24/16 17:30:32 Wrote metrics file example_workflow-0.dag.metrics.
10/24/16 17:30:32 Reporting metrics to Pegasus metrics server(s); output is in example_workflow-0.dag.metrics.out.
10/24/16 17:30:32 Running command </usr/lib/condor/libexec/condor_dagman_metrics_reporter -f example_workflow-0.dag.metrics -t 100>
10/24/16 17:30:32 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
10/24/16 17:30:32 **** condor_scheduniv_exec.382.0 (condor_DAGMAN) pid 18906 EXITING WITH STATUS 0
