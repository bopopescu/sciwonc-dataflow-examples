01/19/17 18:05:40 ******************************************************
01/19/17 18:05:40 ** condor_scheduniv_exec.9887.0 (CONDOR_DAGMAN) STARTING UP
01/19/17 18:05:40 ** /usr/bin/condor_dagman
01/19/17 18:05:40 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
01/19/17 18:05:40 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
01/19/17 18:05:40 ** $CondorVersion: 8.4.8 Jun 30 2016 BuildID: 373513 $
01/19/17 18:05:40 ** $CondorPlatform: x86_64_Ubuntu14 $
01/19/17 18:05:40 ** PID = 81893
01/19/17 18:05:40 ** Log last touched time unavailable (No such file or directory)
01/19/17 18:05:40 ******************************************************
01/19/17 18:05:40 Using config source: /etc/condor/condor_config
01/19/17 18:05:40 Using local config sources: 
01/19/17 18:05:40    /etc/condor/condor_config.local
01/19/17 18:05:40 config Macros = 63, Sorted = 63, StringBytes = 1965, TablesBytes = 2308
01/19/17 18:05:40 CLASSAD_CACHING is ENABLED
01/19/17 18:05:40 Daemon Log is logging: D_ALWAYS D_ERROR
01/19/17 18:05:40 DaemonCore: No command port requested.
01/19/17 18:05:40 DAGMAN_USE_STRICT setting: 1
01/19/17 18:05:40 DAGMAN_VERBOSITY setting: 3
01/19/17 18:05:40 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
01/19/17 18:05:40 DAGMAN_DEBUG_CACHE_ENABLE setting: False
01/19/17 18:05:40 DAGMAN_SUBMIT_DELAY setting: 0
01/19/17 18:05:40 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
01/19/17 18:05:40 DAGMAN_STARTUP_CYCLE_DETECT setting: False
01/19/17 18:05:40 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
01/19/17 18:05:40 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
01/19/17 18:05:40 DAGMAN_DEFAULT_PRIORITY setting: 0
01/19/17 18:05:40 DAGMAN_SUPPRESS_NOTIFICATION setting: True
01/19/17 18:05:40 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
01/19/17 18:05:40 DAGMAN_RETRY_SUBMIT_FIRST setting: True
01/19/17 18:05:40 DAGMAN_RETRY_NODE_FIRST setting: False
01/19/17 18:05:40 DAGMAN_MAX_JOBS_IDLE setting: 1000
01/19/17 18:05:40 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
01/19/17 18:05:40 DAGMAN_MAX_PRE_SCRIPTS setting: 20
01/19/17 18:05:40 DAGMAN_MAX_POST_SCRIPTS setting: 20
01/19/17 18:05:40 DAGMAN_ALLOW_LOG_ERROR setting: False
01/19/17 18:05:40 DAGMAN_MUNGE_NODE_NAMES setting: True
01/19/17 18:05:40 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
01/19/17 18:05:40 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
01/19/17 18:05:40 DAGMAN_ALWAYS_RUN_POST setting: True
01/19/17 18:05:40 DAGMAN_ABORT_DUPLICATES setting: True
01/19/17 18:05:40 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
01/19/17 18:05:40 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
01/19/17 18:05:40 DAGMAN_AUTO_RESCUE setting: True
01/19/17 18:05:40 DAGMAN_MAX_RESCUE_NUM setting: 100
01/19/17 18:05:40 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
01/19/17 18:05:40 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
01/19/17 18:05:40 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
01/19/17 18:05:40 DAGMAN_MAX_JOB_HOLDS setting: 100
01/19/17 18:05:40 DAGMAN_HOLD_CLAIM_TIME setting: 20
01/19/17 18:05:40 ALL_DEBUG setting: 
01/19/17 18:05:40 DAGMAN_DEBUG setting: 
01/19/17 18:05:40 DAGMAN_SUPPRESS_JOB_LOGS setting: False
01/19/17 18:05:40 argv[0] == "condor_scheduniv_exec.9887.0"
01/19/17 18:05:40 argv[1] == "-Lockfile"
01/19/17 18:05:40 argv[2] == "example_workflow-0.dag.lock"
01/19/17 18:05:40 argv[3] == "-AutoRescue"
01/19/17 18:05:40 argv[4] == "1"
01/19/17 18:05:40 argv[5] == "-DoRescueFrom"
01/19/17 18:05:40 argv[6] == "0"
01/19/17 18:05:40 argv[7] == "-Dag"
01/19/17 18:05:40 argv[8] == "example_workflow-0.dag"
01/19/17 18:05:40 argv[9] == "-MaxPost"
01/19/17 18:05:40 argv[10] == "20"
01/19/17 18:05:40 argv[11] == "-Suppress_notification"
01/19/17 18:05:40 argv[12] == "-CsdVersion"
01/19/17 18:05:40 argv[13] == "$CondorVersion: 8.4.8 Jun 30 2016 BuildID: 373513 $"
01/19/17 18:05:40 argv[14] == "-Dagman"
01/19/17 18:05:40 argv[15] == "/usr/bin/condor_dagman"
01/19/17 18:05:40 Warning: failed to get attribute DAGNodeName
01/19/17 18:05:40 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
01/19/17 18:05:40 Default node log file is: </home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log>
01/19/17 18:05:40 DAG Lockfile will be written to example_workflow-0.dag.lock
01/19/17 18:05:40 DAG Input file is example_workflow-0.dag
01/19/17 18:05:40 Parsing 1 dagfiles
01/19/17 18:05:40 Parsing example_workflow-0.dag ...
01/19/17 18:05:40 Warning: category stage-out has no throttle value set
01/19/17 18:05:40 Warning: category stage-in has no throttle value set
01/19/17 18:05:40 Dag contains 32 total jobs
01/19/17 18:05:40 Sleeping for 3 seconds to ensure ProcessId uniqueness
01/19/17 18:05:43 Bootstrapping...
01/19/17 18:05:43 Number of pre-completed nodes: 0
01/19/17 18:05:43 MultiLogFiles: truncating log file /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:05:43 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:05:43 Of 32 nodes total:
01/19/17 18:05:43  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:05:43   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:05:43     0       0        0       0       1         31        0
01/19/17 18:05:43 0 job proc(s) currently held
01/19/17 18:05:43 Registering condor_event_timer...
01/19/17 18:05:44 Submitting Condor Node create_dir_example_workflow_0_local job(s)...
01/19/17 18:05:44 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:05:44 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:05:44 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:05:44 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'create_dir_example_workflow_0_local -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'create_dir_example_workflow_0_local -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/create_dir_example_workflow_0_local.sub
01/19/17 18:05:44 From submit: Submitting job(s).
01/19/17 18:05:44 From submit: 1 job(s) submitted to cluster 9888.
01/19/17 18:05:44 	assigned Condor ID (9888.0.0)
01/19/17 18:05:44 Just submitted 1 job this cycle...
01/19/17 18:05:44 Currently monitoring 1 Condor log file(s)
01/19/17 18:05:44 Reassigning the id of job create_dir_example_workflow_0_local from (9888.0.0) to (9888.0.0)
01/19/17 18:05:44 Event: ULOG_SUBMIT for Condor Node create_dir_example_workflow_0_local (9888.0.0)
01/19/17 18:05:44 Number of idle job procs: 1
01/19/17 18:05:44 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:05:44 Of 32 nodes total:
01/19/17 18:05:44  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:05:44   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:05:44     0       0        1       0       0         31        0
01/19/17 18:05:44 0 job proc(s) currently held
01/19/17 18:05:49 Currently monitoring 1 Condor log file(s)
01/19/17 18:05:49 Event: ULOG_EXECUTE for Condor Node create_dir_example_workflow_0_local (9888.0.0)
01/19/17 18:05:49 Number of idle job procs: 0
01/19/17 18:05:49 Event: ULOG_JOB_TERMINATED for Condor Node create_dir_example_workflow_0_local (9888.0.0)
01/19/17 18:05:49 Number of idle job procs: 0
01/19/17 18:05:49 Node create_dir_example_workflow_0_local job proc (9888.0.0) completed successfully.
01/19/17 18:05:49 Node create_dir_example_workflow_0_local job completed
01/19/17 18:05:49 Running POST script of Node create_dir_example_workflow_0_local...
01/19/17 18:05:49 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:05:49 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:05:49 Of 32 nodes total:
01/19/17 18:05:49  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:05:49   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:05:49     0       0        0       1       0         31        0
01/19/17 18:05:49 0 job proc(s) currently held
01/19/17 18:05:49 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9888.0.0)
01/19/17 18:05:54 Currently monitoring 1 Condor log file(s)
01/19/17 18:05:54 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node create_dir_example_workflow_0_local (9888.0.0)
01/19/17 18:05:54 POST Script of Node create_dir_example_workflow_0_local completed successfully.
01/19/17 18:05:54 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:05:54 Of 32 nodes total:
01/19/17 18:05:54  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:05:54   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:05:54     1       0        0       0      12         19        0
01/19/17 18:05:54 0 job proc(s) currently held
01/19/17 18:05:59 Submitting Condor Node stage_in_local_local_0_0 job(s)...
01/19/17 18:05:59 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:05:59 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:05:59 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:05:59 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_0_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_0_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_0_0.sub
01/19/17 18:05:59 From submit: Submitting job(s).
01/19/17 18:05:59 From submit: 1 job(s) submitted to cluster 9889.
01/19/17 18:05:59 	assigned Condor ID (9889.0.0)
01/19/17 18:05:59 Submitting Condor Node stage_in_local_local_4_0 job(s)...
01/19/17 18:05:59 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:05:59 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:05:59 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:05:59 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_4_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_4_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_4_0.sub
01/19/17 18:05:59 From submit: Submitting job(s).
01/19/17 18:05:59 From submit: 1 job(s) submitted to cluster 9890.
01/19/17 18:05:59 	assigned Condor ID (9890.0.0)
01/19/17 18:05:59 Submitting Condor Node stage_in_local_local_1_0 job(s)...
01/19/17 18:05:59 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:05:59 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:05:59 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:05:59 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_1_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_1_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_1_0.sub
01/19/17 18:05:59 From submit: Submitting job(s).
01/19/17 18:05:59 From submit: 1 job(s) submitted to cluster 9891.
01/19/17 18:05:59 	assigned Condor ID (9891.0.0)
01/19/17 18:05:59 Submitting Condor Node stage_in_local_local_2_0 job(s)...
01/19/17 18:05:59 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:05:59 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:05:59 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:05:59 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_2_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_2_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_2_0.sub
01/19/17 18:06:00 From submit: Submitting job(s).
01/19/17 18:06:00 From submit: 1 job(s) submitted to cluster 9892.
01/19/17 18:06:00 	assigned Condor ID (9892.0.0)
01/19/17 18:06:00 Submitting Condor Node stage_in_local_local_2_1 job(s)...
01/19/17 18:06:00 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:00 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:00 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:00 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_2_1 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_2_1 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_2_1.sub
01/19/17 18:06:00 From submit: Submitting job(s).
01/19/17 18:06:00 From submit: 1 job(s) submitted to cluster 9893.
01/19/17 18:06:00 	assigned Condor ID (9893.0.0)
01/19/17 18:06:00 Just submitted 5 jobs this cycle...
01/19/17 18:06:00 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:00 Reassigning the id of job stage_in_local_local_0_0 from (9889.0.0) to (9889.0.0)
01/19/17 18:06:00 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_0_0 (9889.0.0)
01/19/17 18:06:00 Number of idle job procs: 1
01/19/17 18:06:00 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_0_0 (9889.0.0)
01/19/17 18:06:00 Number of idle job procs: 0
01/19/17 18:06:00 Reassigning the id of job stage_in_local_local_4_0 from (9890.0.0) to (9890.0.0)
01/19/17 18:06:00 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_4_0 (9890.0.0)
01/19/17 18:06:00 Number of idle job procs: 1
01/19/17 18:06:00 Reassigning the id of job stage_in_local_local_1_0 from (9891.0.0) to (9891.0.0)
01/19/17 18:06:00 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_1_0 (9891.0.0)
01/19/17 18:06:00 Number of idle job procs: 2
01/19/17 18:06:00 Reassigning the id of job stage_in_local_local_2_0 from (9892.0.0) to (9892.0.0)
01/19/17 18:06:00 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_2_0 (9892.0.0)
01/19/17 18:06:00 Number of idle job procs: 3
01/19/17 18:06:00 Reassigning the id of job stage_in_local_local_2_1 from (9893.0.0) to (9893.0.0)
01/19/17 18:06:00 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_2_1 (9893.0.0)
01/19/17 18:06:00 Number of idle job procs: 4
01/19/17 18:06:00 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:06:00 Of 32 nodes total:
01/19/17 18:06:00  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:06:00   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:06:00     1       0        5       0       7         19        0
01/19/17 18:06:00 0 job proc(s) currently held
01/19/17 18:06:05 Submitting Condor Node stage_in_remote_local_0_0 job(s)...
01/19/17 18:06:05 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:05 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:05 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:05 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_0_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_0_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_0_0.sub
01/19/17 18:06:05 From submit: Submitting job(s).
01/19/17 18:06:05 From submit: 1 job(s) submitted to cluster 9894.
01/19/17 18:06:05 	assigned Condor ID (9894.0.0)
01/19/17 18:06:05 Submitting Condor Node stage_in_remote_local_4_0 job(s)...
01/19/17 18:06:05 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:05 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:05 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:05 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_4_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_4_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_4_0.sub
01/19/17 18:06:05 From submit: Submitting job(s).
01/19/17 18:06:05 From submit: 1 job(s) submitted to cluster 9895.
01/19/17 18:06:05 	assigned Condor ID (9895.0.0)
01/19/17 18:06:05 Submitting Condor Node stage_in_remote_local_1_0 job(s)...
01/19/17 18:06:05 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:05 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:05 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:05 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_1_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_1_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_1_0.sub
01/19/17 18:06:05 From submit: Submitting job(s).
01/19/17 18:06:05 From submit: 1 job(s) submitted to cluster 9896.
01/19/17 18:06:05 	assigned Condor ID (9896.0.0)
01/19/17 18:06:05 Submitting Condor Node stage_in_local_local_3_1 job(s)...
01/19/17 18:06:05 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:05 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:05 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:05 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_3_1 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_3_1 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_3_1.sub
01/19/17 18:06:05 From submit: Submitting job(s).
01/19/17 18:06:05 From submit: 1 job(s) submitted to cluster 9897.
01/19/17 18:06:05 	assigned Condor ID (9897.0.0)
01/19/17 18:06:05 Submitting Condor Node stage_in_local_local_3_0 job(s)...
01/19/17 18:06:05 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:05 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:05 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:05 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_local_local_3_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_local_local_3_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_local_local_3_0.sub
01/19/17 18:06:05 From submit: Submitting job(s).
01/19/17 18:06:05 From submit: 1 job(s) submitted to cluster 9898.
01/19/17 18:06:05 	assigned Condor ID (9898.0.0)
01/19/17 18:06:05 Just submitted 5 jobs this cycle...
01/19/17 18:06:05 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:05 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_0_0 (9889.0.0)
01/19/17 18:06:05 Number of idle job procs: 4
01/19/17 18:06:05 Node stage_in_local_local_0_0 job proc (9889.0.0) completed successfully.
01/19/17 18:06:05 Node stage_in_local_local_0_0 job completed
01/19/17 18:06:05 Running POST script of Node stage_in_local_local_0_0...
01/19/17 18:06:05 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:05 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_2_0 (9892.0.0)
01/19/17 18:06:05 Number of idle job procs: 3
01/19/17 18:06:05 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_1_0 (9891.0.0)
01/19/17 18:06:05 Number of idle job procs: 2
01/19/17 18:06:05 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_2_1 (9893.0.0)
01/19/17 18:06:05 Number of idle job procs: 1
01/19/17 18:06:05 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_4_0 (9890.0.0)
01/19/17 18:06:05 Number of idle job procs: 0
01/19/17 18:06:05 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_1_0 (9891.0.0)
01/19/17 18:06:05 Number of idle job procs: 0
01/19/17 18:06:05 Node stage_in_local_local_1_0 job proc (9891.0.0) completed successfully.
01/19/17 18:06:05 Node stage_in_local_local_1_0 job completed
01/19/17 18:06:05 Running POST script of Node stage_in_local_local_1_0...
01/19/17 18:06:05 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:05 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_4_0 (9890.0.0)
01/19/17 18:06:05 Number of idle job procs: 0
01/19/17 18:06:05 Node stage_in_local_local_4_0 job proc (9890.0.0) completed successfully.
01/19/17 18:06:05 Node stage_in_local_local_4_0 job completed
01/19/17 18:06:05 Running POST script of Node stage_in_local_local_4_0...
01/19/17 18:06:05 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:05 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_2_1 (9893.0.0)
01/19/17 18:06:05 Number of idle job procs: 0
01/19/17 18:06:05 Node stage_in_local_local_2_1 job proc (9893.0.0) completed successfully.
01/19/17 18:06:05 Node stage_in_local_local_2_1 job completed
01/19/17 18:06:05 Running POST script of Node stage_in_local_local_2_1...
01/19/17 18:06:05 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:05 Reassigning the id of job stage_in_remote_local_0_0 from (9894.0.0) to (9894.0.0)
01/19/17 18:06:05 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_0_0 (9894.0.0)
01/19/17 18:06:05 Number of idle job procs: 1
01/19/17 18:06:05 Reassigning the id of job stage_in_remote_local_4_0 from (9895.0.0) to (9895.0.0)
01/19/17 18:06:05 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_4_0 (9895.0.0)
01/19/17 18:06:05 Number of idle job procs: 2
01/19/17 18:06:05 Reassigning the id of job stage_in_remote_local_1_0 from (9896.0.0) to (9896.0.0)
01/19/17 18:06:05 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_1_0 (9896.0.0)
01/19/17 18:06:05 Number of idle job procs: 3
01/19/17 18:06:05 Reassigning the id of job stage_in_local_local_3_1 from (9897.0.0) to (9897.0.0)
01/19/17 18:06:05 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_3_1 (9897.0.0)
01/19/17 18:06:05 Number of idle job procs: 4
01/19/17 18:06:05 Reassigning the id of job stage_in_local_local_3_0 from (9898.0.0) to (9898.0.0)
01/19/17 18:06:05 Event: ULOG_SUBMIT for Condor Node stage_in_local_local_3_0 (9898.0.0)
01/19/17 18:06:05 Number of idle job procs: 5
01/19/17 18:06:05 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:06:05 Of 32 nodes total:
01/19/17 18:06:05  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:06:05   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:06:05     1       0        6       4       2         19        0
01/19/17 18:06:05 0 job proc(s) currently held
01/19/17 18:06:05 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9889.0.0)
01/19/17 18:06:05 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9893.0.0)
01/19/17 18:06:05 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9891.0.0)
01/19/17 18:06:05 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9890.0.0)
01/19/17 18:06:10 Submitting Condor Node stage_in_remote_local_3_1 job(s)...
01/19/17 18:06:10 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:10 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:10 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:10 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_3_1 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_3_1 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_3_1.sub
01/19/17 18:06:10 From submit: Submitting job(s).
01/19/17 18:06:10 From submit: 1 job(s) submitted to cluster 9899.
01/19/17 18:06:11 	assigned Condor ID (9899.0.0)
01/19/17 18:06:11 Submitting Condor Node stage_in_remote_local_3_0 job(s)...
01/19/17 18:06:11 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:11 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:11 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:11 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_in_remote_local_3_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_in_remote_local_3_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"create_dir_example_workflow_0_local" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_in_remote_local_3_0.sub
01/19/17 18:06:11 From submit: Submitting job(s).
01/19/17 18:06:11 From submit: 1 job(s) submitted to cluster 9900.
01/19/17 18:06:11 	assigned Condor ID (9900.0.0)
01/19/17 18:06:11 Just submitted 2 jobs this cycle...
01/19/17 18:06:11 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:11 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_0_0 (9889.0.0)
01/19/17 18:06:11 POST Script of Node stage_in_local_local_0_0 completed successfully.
01/19/17 18:06:11 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_2_1 (9893.0.0)
01/19/17 18:06:11 POST Script of Node stage_in_local_local_2_1 completed successfully.
01/19/17 18:06:11 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_1_0 (9891.0.0)
01/19/17 18:06:11 POST Script of Node stage_in_local_local_1_0 completed successfully.
01/19/17 18:06:11 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_4_0 (9890.0.0)
01/19/17 18:06:11 POST Script of Node stage_in_local_local_4_0 completed successfully.
01/19/17 18:06:11 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_2_0 (9892.0.0)
01/19/17 18:06:11 Number of idle job procs: 5
01/19/17 18:06:11 Node stage_in_local_local_2_0 job proc (9892.0.0) completed successfully.
01/19/17 18:06:11 Node stage_in_local_local_2_0 job completed
01/19/17 18:06:11 Running POST script of Node stage_in_local_local_2_0...
01/19/17 18:06:11 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:11 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_4_0 (9895.0.0)
01/19/17 18:06:11 Number of idle job procs: 4
01/19/17 18:06:11 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_3_0 (9898.0.0)
01/19/17 18:06:11 Number of idle job procs: 3
01/19/17 18:06:11 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_0_0 (9894.0.0)
01/19/17 18:06:11 Number of idle job procs: 2
01/19/17 18:06:11 Event: ULOG_EXECUTE for Condor Node stage_in_local_local_3_1 (9897.0.0)
01/19/17 18:06:11 Number of idle job procs: 1
01/19/17 18:06:11 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_1_0 (9896.0.0)
01/19/17 18:06:11 Number of idle job procs: 0
01/19/17 18:06:11 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_4_0 (9895.0.0)
01/19/17 18:06:11 Number of idle job procs: 0
01/19/17 18:06:11 Node stage_in_remote_local_4_0 job proc (9895.0.0) completed successfully.
01/19/17 18:06:11 Node stage_in_remote_local_4_0 job completed
01/19/17 18:06:11 Running POST script of Node stage_in_remote_local_4_0...
01/19/17 18:06:11 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:11 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_1_0 (9896.0.0)
01/19/17 18:06:11 Number of idle job procs: 0
01/19/17 18:06:11 Node stage_in_remote_local_1_0 job proc (9896.0.0) completed successfully.
01/19/17 18:06:11 Node stage_in_remote_local_1_0 job completed
01/19/17 18:06:11 Running POST script of Node stage_in_remote_local_1_0...
01/19/17 18:06:11 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:11 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_0_0 (9894.0.0)
01/19/17 18:06:11 Number of idle job procs: 0
01/19/17 18:06:11 Node stage_in_remote_local_0_0 job proc (9894.0.0) completed successfully.
01/19/17 18:06:11 Node stage_in_remote_local_0_0 job completed
01/19/17 18:06:11 Running POST script of Node stage_in_remote_local_0_0...
01/19/17 18:06:11 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:11 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_3_1 (9897.0.0)
01/19/17 18:06:11 Number of idle job procs: 0
01/19/17 18:06:11 Node stage_in_local_local_3_1 job proc (9897.0.0) completed successfully.
01/19/17 18:06:11 Node stage_in_local_local_3_1 job completed
01/19/17 18:06:11 Running POST script of Node stage_in_local_local_3_1...
01/19/17 18:06:11 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:11 Reassigning the id of job stage_in_remote_local_3_1 from (9899.0.0) to (9899.0.0)
01/19/17 18:06:11 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_3_1 (9899.0.0)
01/19/17 18:06:11 Number of idle job procs: 1
01/19/17 18:06:11 Reassigning the id of job stage_in_remote_local_3_0 from (9900.0.0) to (9900.0.0)
01/19/17 18:06:11 Event: ULOG_SUBMIT for Condor Node stage_in_remote_local_3_0 (9900.0.0)
01/19/17 18:06:11 Number of idle job procs: 2
01/19/17 18:06:11 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:06:11 Of 32 nodes total:
01/19/17 18:06:11  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:06:11   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:06:11     5       0        3       5       0         19        0
01/19/17 18:06:11 0 job proc(s) currently held
01/19/17 18:06:11 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9892.0.0)
01/19/17 18:06:11 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9896.0.0)
01/19/17 18:06:11 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9895.0.0)
01/19/17 18:06:11 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9894.0.0)
01/19/17 18:06:12 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9897.0.0)
01/19/17 18:06:16 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:16 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_2_0 (9892.0.0)
01/19/17 18:06:16 POST Script of Node stage_in_local_local_2_0 completed successfully.
01/19/17 18:06:16 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_1_0 (9896.0.0)
01/19/17 18:06:16 POST Script of Node stage_in_remote_local_1_0 completed successfully.
01/19/17 18:06:16 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_local_local_3_0 (9898.0.0)
01/19/17 18:06:16 Number of idle job procs: 2
01/19/17 18:06:16 Node stage_in_local_local_3_0 job proc (9898.0.0) completed successfully.
01/19/17 18:06:16 Node stage_in_local_local_3_0 job completed
01/19/17 18:06:16 Running POST script of Node stage_in_local_local_3_0...
01/19/17 18:06:16 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:16 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_3_0 (9900.0.0)
01/19/17 18:06:16 Number of idle job procs: 1
01/19/17 18:06:16 Event: ULOG_EXECUTE for Condor Node stage_in_remote_local_3_1 (9899.0.0)
01/19/17 18:06:16 Number of idle job procs: 0
01/19/17 18:06:16 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_4_0 (9895.0.0)
01/19/17 18:06:16 POST Script of Node stage_in_remote_local_4_0 completed successfully.
01/19/17 18:06:16 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_0_0 (9894.0.0)
01/19/17 18:06:16 POST Script of Node stage_in_remote_local_0_0 completed successfully.
01/19/17 18:06:16 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_3_1 (9897.0.0)
01/19/17 18:06:16 POST Script of Node stage_in_local_local_3_1 completed successfully.
01/19/17 18:06:16 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_3_1 (9899.0.0)
01/19/17 18:06:16 Number of idle job procs: 0
01/19/17 18:06:16 Node stage_in_remote_local_3_1 job proc (9899.0.0) completed successfully.
01/19/17 18:06:16 Node stage_in_remote_local_3_1 job completed
01/19/17 18:06:16 Running POST script of Node stage_in_remote_local_3_1...
01/19/17 18:06:16 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:16 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:06:16 Of 32 nodes total:
01/19/17 18:06:16  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:06:16   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:06:16    10       0        1       2       1         18        0
01/19/17 18:06:16 0 job proc(s) currently held
01/19/17 18:06:16 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9898.0.0)
01/19/17 18:06:16 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9899.0.0)
01/19/17 18:06:21 Submitting Condor Node init_0_ID0000001 job(s)...
01/19/17 18:06:21 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:06:21 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:06:21 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:06:21 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'init_0_ID0000001 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'init_0_ID0000001 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_0_0,stage_in_remote_local_0_0" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/init_0_ID0000001.sub
01/19/17 18:06:21 From submit: Submitting job(s).
01/19/17 18:06:21 From submit: 1 job(s) submitted to cluster 9901.
01/19/17 18:06:21 	assigned Condor ID (9901.0.0)
01/19/17 18:06:21 Just submitted 1 job this cycle...
01/19/17 18:06:21 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:21 Event: ULOG_JOB_TERMINATED for Condor Node stage_in_remote_local_3_0 (9900.0.0)
01/19/17 18:06:21 Number of idle job procs: 0
01/19/17 18:06:21 Node stage_in_remote_local_3_0 job proc (9900.0.0) completed successfully.
01/19/17 18:06:21 Node stage_in_remote_local_3_0 job completed
01/19/17 18:06:21 Running POST script of Node stage_in_remote_local_3_0...
01/19/17 18:06:21 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:06:21 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_local_local_3_0 (9898.0.0)
01/19/17 18:06:21 POST Script of Node stage_in_local_local_3_0 completed successfully.
01/19/17 18:06:21 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_3_1 (9899.0.0)
01/19/17 18:06:21 POST Script of Node stage_in_remote_local_3_1 completed successfully.
01/19/17 18:06:21 Reassigning the id of job init_0_ID0000001 from (9901.0.0) to (9901.0.0)
01/19/17 18:06:21 Event: ULOG_SUBMIT for Condor Node init_0_ID0000001 (9901.0.0)
01/19/17 18:06:21 Number of idle job procs: 1
01/19/17 18:06:21 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:06:21 Of 32 nodes total:
01/19/17 18:06:21  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:06:21   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:06:21    12       0        1       1       0         18        0
01/19/17 18:06:21 0 job proc(s) currently held
01/19/17 18:06:21 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9900.0.0)
01/19/17 18:06:26 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:26 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_in_remote_local_3_0 (9900.0.0)
01/19/17 18:06:26 POST Script of Node stage_in_remote_local_3_0 completed successfully.
01/19/17 18:06:26 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:06:26 Of 32 nodes total:
01/19/17 18:06:26  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:06:26   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:06:26    13       0        1       0       0         18        0
01/19/17 18:06:26 0 job proc(s) currently held
01/19/17 18:06:41 Currently monitoring 1 Condor log file(s)
01/19/17 18:06:41 Event: ULOG_EXECUTE for Condor Node init_0_ID0000001 (9901.0.0)
01/19/17 18:06:41 Number of idle job procs: 0
01/19/17 18:16:42 601 seconds since last log event
01/19/17 18:16:42 Pending DAG nodes:
01/19/17 18:16:42   Node init_0_ID0000001, Condor ID 9901, status STATUS_SUBMITTED
01/19/17 18:23:27 Currently monitoring 1 Condor log file(s)
01/19/17 18:23:27 Event: ULOG_JOB_TERMINATED for Condor Node init_0_ID0000001 (9901.0.0)
01/19/17 18:23:27 Number of idle job procs: 0
01/19/17 18:23:27 Node init_0_ID0000001 job proc (9901.0.0) completed successfully.
01/19/17 18:23:27 Node init_0_ID0000001 job completed
01/19/17 18:23:27 Running POST script of Node init_0_ID0000001...
01/19/17 18:23:27 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:23:27 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:23:27 Of 32 nodes total:
01/19/17 18:23:27  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:23:27   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:23:27    13       0        0       1       0         18        0
01/19/17 18:23:27 0 job proc(s) currently held
01/19/17 18:23:27 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9901.0.0)
01/19/17 18:23:32 Currently monitoring 1 Condor log file(s)
01/19/17 18:23:32 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node init_0_ID0000001 (9901.0.0)
01/19/17 18:23:32 POST Script of Node init_0_ID0000001 completed successfully.
01/19/17 18:23:32 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:23:32 Of 32 nodes total:
01/19/17 18:23:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:23:32   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:23:32    14       0        0       0       2         16        0
01/19/17 18:23:32 0 job proc(s) currently held
01/19/17 18:23:37 Submitting Condor Node clean_up_local_level_3_0 job(s)...
01/19/17 18:23:37 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:23:37 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:23:37 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:23:37 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_3_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_3_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"init_0_ID0000001" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_3_0.sub
01/19/17 18:23:37 From submit: Submitting job(s).
01/19/17 18:23:37 From submit: 1 job(s) submitted to cluster 9902.
01/19/17 18:23:37 	assigned Condor ID (9902.0.0)
01/19/17 18:23:37 Submitting Condor Node computeusergroup_0_ID0000002 job(s)...
01/19/17 18:23:37 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 18:23:37 Masking the events recorded in the DAGMAN workflow log
01/19/17 18:23:37 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 18:23:37 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'computeusergroup_0_ID0000002 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'computeusergroup_0_ID0000002 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_1_0,stage_in_remote_local_1_0,init_0_ID0000001" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/computeusergroup_0_ID0000002.sub
01/19/17 18:23:37 From submit: Submitting job(s).
01/19/17 18:23:37 From submit: 1 job(s) submitted to cluster 9903.
01/19/17 18:23:37 	assigned Condor ID (9903.0.0)
01/19/17 18:23:37 Just submitted 2 jobs this cycle...
01/19/17 18:23:37 Currently monitoring 1 Condor log file(s)
01/19/17 18:23:37 Reassigning the id of job clean_up_local_level_3_0 from (9902.0.0) to (9902.0.0)
01/19/17 18:23:37 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_3_0 (9902.0.0)
01/19/17 18:23:37 Number of idle job procs: 1
01/19/17 18:23:37 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_3_0 (9902.0.0)
01/19/17 18:23:37 Number of idle job procs: 0
01/19/17 18:23:37 Reassigning the id of job computeusergroup_0_ID0000002 from (9903.0.0) to (9903.0.0)
01/19/17 18:23:37 Event: ULOG_SUBMIT for Condor Node computeusergroup_0_ID0000002 (9903.0.0)
01/19/17 18:23:37 Number of idle job procs: 1
01/19/17 18:23:37 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:23:37 Of 32 nodes total:
01/19/17 18:23:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:23:37   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:23:37    14       0        2       0       0         16        0
01/19/17 18:23:37 0 job proc(s) currently held
01/19/17 18:23:43 Currently monitoring 1 Condor log file(s)
01/19/17 18:23:43 Event: ULOG_EXECUTE for Condor Node computeusergroup_0_ID0000002 (9903.0.0)
01/19/17 18:23:43 Number of idle job procs: 0
01/19/17 18:23:43 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_3_0 (9902.0.0)
01/19/17 18:23:43 Number of idle job procs: 0
01/19/17 18:23:43 Node clean_up_local_level_3_0 job proc (9902.0.0) completed successfully.
01/19/17 18:23:43 Node clean_up_local_level_3_0 job completed
01/19/17 18:23:43 Running POST script of Node clean_up_local_level_3_0...
01/19/17 18:23:43 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 18:23:43 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:23:43 Of 32 nodes total:
01/19/17 18:23:43  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:23:43   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:23:43    14       0        1       1       0         16        0
01/19/17 18:23:43 0 job proc(s) currently held
01/19/17 18:23:43 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9902.0.0)
01/19/17 18:23:48 Currently monitoring 1 Condor log file(s)
01/19/17 18:23:48 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_3_0 (9902.0.0)
01/19/17 18:23:48 POST Script of Node clean_up_local_level_3_0 completed successfully.
01/19/17 18:23:48 DAG status: 0 (DAG_STATUS_OK)
01/19/17 18:23:48 Of 32 nodes total:
01/19/17 18:23:48  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 18:23:48   ===     ===      ===     ===     ===        ===      ===
01/19/17 18:23:48    15       0        1       0       0         16        0
01/19/17 18:23:48 0 job proc(s) currently held
01/19/17 18:33:48 600 seconds since last log event
01/19/17 18:33:48 Pending DAG nodes:
01/19/17 18:33:48   Node computeusergroup_0_ID0000002, Condor ID 9903, status STATUS_SUBMITTED
01/19/17 18:43:49 1201 seconds since last log event
01/19/17 18:43:49 Pending DAG nodes:
01/19/17 18:43:49   Node computeusergroup_0_ID0000002, Condor ID 9903, status STATUS_SUBMITTED
01/19/17 18:53:50 1802 seconds since last log event
01/19/17 18:53:50 Pending DAG nodes:
01/19/17 18:53:50   Node computeusergroup_0_ID0000002, Condor ID 9903, status STATUS_SUBMITTED
01/19/17 19:03:50 2402 seconds since last log event
01/19/17 19:03:50 Pending DAG nodes:
01/19/17 19:03:50   Node computeusergroup_0_ID0000002, Condor ID 9903, status STATUS_SUBMITTED
01/19/17 19:13:51 3003 seconds since last log event
01/19/17 19:13:51 Pending DAG nodes:
01/19/17 19:13:51   Node computeusergroup_0_ID0000002, Condor ID 9903, status STATUS_SUBMITTED
01/19/17 19:19:06 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:06 Event: ULOG_JOB_TERMINATED for Condor Node computeusergroup_0_ID0000002 (9903.0.0)
01/19/17 19:19:06 Number of idle job procs: 0
01/19/17 19:19:06 Node computeusergroup_0_ID0000002 job proc (9903.0.0) completed successfully.
01/19/17 19:19:06 Node computeusergroup_0_ID0000002 job completed
01/19/17 19:19:06 Running POST script of Node computeusergroup_0_ID0000002...
01/19/17 19:19:06 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:19:06 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:19:06 Of 32 nodes total:
01/19/17 19:19:06  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:19:06   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:19:06    15       0        0       1       0         16        0
01/19/17 19:19:06 0 job proc(s) currently held
01/19/17 19:19:06 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9903.0.0)
01/19/17 19:19:11 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:11 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node computeusergroup_0_ID0000002 (9903.0.0)
01/19/17 19:19:11 POST Script of Node computeusergroup_0_ID0000002 completed successfully.
01/19/17 19:19:11 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:19:11 Of 32 nodes total:
01/19/17 19:19:11  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:19:11   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:19:11    16       0        0       0       6         10        0
01/19/17 19:19:11 0 job proc(s) currently held
01/19/17 19:19:16 Submitting Condor Node clean_up_local_level_4_0 job(s)...
01/19/17 19:19:16 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:19:16 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:19:16 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:19:16 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_4_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_4_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"computeusergroup_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_4_0.sub
01/19/17 19:19:16 From submit: Submitting job(s).
01/19/17 19:19:16 From submit: 1 job(s) submitted to cluster 9904.
01/19/17 19:19:16 	assigned Condor ID (9904.0.0)
01/19/17 19:19:16 Submitting Condor Node sessioncompute_1_ID0000004 job(s)...
01/19/17 19:19:16 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:19:16 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:19:16 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:19:16 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'sessioncompute_1_ID0000004 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'sessioncompute_1_ID0000004 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_2_0,computeusergroup_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/sessioncompute_1_ID0000004.sub
01/19/17 19:19:17 From submit: Submitting job(s).
01/19/17 19:19:17 From submit: 1 job(s) submitted to cluster 9905.
01/19/17 19:19:17 	assigned Condor ID (9905.0.0)
01/19/17 19:19:17 Submitting Condor Node stage_out_local_local_1_0 job(s)...
01/19/17 19:19:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:19:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:19:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:19:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_out_local_local_1_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_out_local_local_1_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"computeusergroup_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_out_local_local_1_0.sub
01/19/17 19:19:17 From submit: Submitting job(s).
01/19/17 19:19:17 From submit: 1 job(s) submitted to cluster 9906.
01/19/17 19:19:17 	assigned Condor ID (9906.0.0)
01/19/17 19:19:17 Submitting Condor Node stage_out_local_local_1_1 job(s)...
01/19/17 19:19:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:19:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:19:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:19:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'stage_out_local_local_1_1 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'stage_out_local_local_1_1 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"computeusergroup_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/stage_out_local_local_1_1.sub
01/19/17 19:19:17 From submit: Submitting job(s).
01/19/17 19:19:17 From submit: 1 job(s) submitted to cluster 9907.
01/19/17 19:19:17 	assigned Condor ID (9907.0.0)
01/19/17 19:19:17 Submitting Condor Node sessioncompute_0_ID0000003 job(s)...
01/19/17 19:19:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:19:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:19:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:19:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'sessioncompute_0_ID0000003 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'sessioncompute_0_ID0000003 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_2_1,computeusergroup_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/sessioncompute_0_ID0000003.sub
01/19/17 19:19:17 From submit: Submitting job(s).
01/19/17 19:19:17 From submit: 1 job(s) submitted to cluster 9908.
01/19/17 19:19:17 	assigned Condor ID (9908.0.0)
01/19/17 19:19:17 Just submitted 5 jobs this cycle...
01/19/17 19:19:17 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:17 Reassigning the id of job clean_up_local_level_4_0 from (9904.0.0) to (9904.0.0)
01/19/17 19:19:17 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_4_0 (9904.0.0)
01/19/17 19:19:17 Number of idle job procs: 1
01/19/17 19:19:17 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_4_0 (9904.0.0)
01/19/17 19:19:17 Number of idle job procs: 0
01/19/17 19:19:17 Reassigning the id of job sessioncompute_1_ID0000004 from (9905.0.0) to (9905.0.0)
01/19/17 19:19:17 Event: ULOG_SUBMIT for Condor Node sessioncompute_1_ID0000004 (9905.0.0)
01/19/17 19:19:17 Number of idle job procs: 1
01/19/17 19:19:17 Reassigning the id of job stage_out_local_local_1_0 from (9906.0.0) to (9906.0.0)
01/19/17 19:19:17 Event: ULOG_SUBMIT for Condor Node stage_out_local_local_1_0 (9906.0.0)
01/19/17 19:19:17 Number of idle job procs: 2
01/19/17 19:19:17 Reassigning the id of job stage_out_local_local_1_1 from (9907.0.0) to (9907.0.0)
01/19/17 19:19:17 Event: ULOG_SUBMIT for Condor Node stage_out_local_local_1_1 (9907.0.0)
01/19/17 19:19:17 Number of idle job procs: 3
01/19/17 19:19:17 Reassigning the id of job sessioncompute_0_ID0000003 from (9908.0.0) to (9908.0.0)
01/19/17 19:19:17 Event: ULOG_SUBMIT for Condor Node sessioncompute_0_ID0000003 (9908.0.0)
01/19/17 19:19:17 Number of idle job procs: 4
01/19/17 19:19:17 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:19:17 Of 32 nodes total:
01/19/17 19:19:17  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:19:17   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:19:17    16       0        5       0       1         10        0
01/19/17 19:19:17 0 job proc(s) currently held
01/19/17 19:19:22 Submitting Condor Node sessioncompute_2_ID0000005 job(s)...
01/19/17 19:19:22 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:19:22 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:19:22 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:19:22 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'sessioncompute_2_ID0000005 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'sessioncompute_2_ID0000005 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_2_0,computeusergroup_0_ID0000002" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/sessioncompute_2_ID0000005.sub
01/19/17 19:19:22 From submit: Submitting job(s).
01/19/17 19:19:22 From submit: 1 job(s) submitted to cluster 9909.
01/19/17 19:19:22 	assigned Condor ID (9909.0.0)
01/19/17 19:19:22 Just submitted 1 job this cycle...
01/19/17 19:19:22 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:22 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_4_0 (9904.0.0)
01/19/17 19:19:22 Number of idle job procs: 4
01/19/17 19:19:22 Node clean_up_local_level_4_0 job proc (9904.0.0) completed successfully.
01/19/17 19:19:22 Node clean_up_local_level_4_0 job completed
01/19/17 19:19:22 Running POST script of Node clean_up_local_level_4_0...
01/19/17 19:19:22 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:19:22 Event: ULOG_EXECUTE for Condor Node stage_out_local_local_1_1 (9907.0.0)
01/19/17 19:19:22 Number of idle job procs: 3
01/19/17 19:19:22 Event: ULOG_EXECUTE for Condor Node stage_out_local_local_1_0 (9906.0.0)
01/19/17 19:19:22 Number of idle job procs: 2
01/19/17 19:19:22 Reassigning the id of job sessioncompute_2_ID0000005 from (9909.0.0) to (9909.0.0)
01/19/17 19:19:22 Event: ULOG_SUBMIT for Condor Node sessioncompute_2_ID0000005 (9909.0.0)
01/19/17 19:19:22 Number of idle job procs: 3
01/19/17 19:19:22 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:19:22 Of 32 nodes total:
01/19/17 19:19:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:19:22   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:19:22    16       0        5       1       0         10        0
01/19/17 19:19:22 0 job proc(s) currently held
01/19/17 19:19:22 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9904.0.0)
01/19/17 19:19:27 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:27 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_4_0 (9904.0.0)
01/19/17 19:19:27 POST Script of Node clean_up_local_level_4_0 completed successfully.
01/19/17 19:19:27 Event: ULOG_JOB_TERMINATED for Condor Node stage_out_local_local_1_1 (9907.0.0)
01/19/17 19:19:27 Number of idle job procs: 3
01/19/17 19:19:27 Node stage_out_local_local_1_1 job proc (9907.0.0) completed successfully.
01/19/17 19:19:27 Node stage_out_local_local_1_1 job completed
01/19/17 19:19:27 Running POST script of Node stage_out_local_local_1_1...
01/19/17 19:19:27 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:19:27 Event: ULOG_JOB_TERMINATED for Condor Node stage_out_local_local_1_0 (9906.0.0)
01/19/17 19:19:27 Number of idle job procs: 3
01/19/17 19:19:27 Node stage_out_local_local_1_0 job proc (9906.0.0) completed successfully.
01/19/17 19:19:27 Node stage_out_local_local_1_0 job completed
01/19/17 19:19:27 Running POST script of Node stage_out_local_local_1_0...
01/19/17 19:19:27 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:19:27 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:19:27 Of 32 nodes total:
01/19/17 19:19:27  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:19:27   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:19:27    17       0        3       2       0         10        0
01/19/17 19:19:27 0 job proc(s) currently held
01/19/17 19:19:28 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9906.0.0)
01/19/17 19:19:28 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9907.0.0)
01/19/17 19:19:32 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:32 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_out_local_local_1_0 (9906.0.0)
01/19/17 19:19:32 POST Script of Node stage_out_local_local_1_0 completed successfully.
01/19/17 19:19:32 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node stage_out_local_local_1_1 (9907.0.0)
01/19/17 19:19:32 POST Script of Node stage_out_local_local_1_1 completed successfully.
01/19/17 19:19:32 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:19:32 Of 32 nodes total:
01/19/17 19:19:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:19:32   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:19:32    19       0        3       0       0         10        0
01/19/17 19:19:32 0 job proc(s) currently held
01/19/17 19:19:42 Currently monitoring 1 Condor log file(s)
01/19/17 19:19:42 Event: ULOG_EXECUTE for Condor Node sessioncompute_2_ID0000005 (9909.0.0)
01/19/17 19:19:42 Number of idle job procs: 2
01/19/17 19:19:42 Event: ULOG_EXECUTE for Condor Node sessioncompute_1_ID0000004 (9905.0.0)
01/19/17 19:19:42 Number of idle job procs: 1
01/19/17 19:19:42 Event: ULOG_EXECUTE for Condor Node sessioncompute_0_ID0000003 (9908.0.0)
01/19/17 19:19:42 Number of idle job procs: 0
01/19/17 19:23:32 Currently monitoring 1 Condor log file(s)
01/19/17 19:23:32 Event: ULOG_JOB_TERMINATED for Condor Node sessioncompute_0_ID0000003 (9908.0.0)
01/19/17 19:23:32 Number of idle job procs: 0
01/19/17 19:23:32 Node sessioncompute_0_ID0000003 job proc (9908.0.0) completed successfully.
01/19/17 19:23:32 Node sessioncompute_0_ID0000003 job completed
01/19/17 19:23:32 Running POST script of Node sessioncompute_0_ID0000003...
01/19/17 19:23:32 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:23:32 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:23:32 Of 32 nodes total:
01/19/17 19:23:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:23:32   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:23:32    19       0        2       1       0         10        0
01/19/17 19:23:32 0 job proc(s) currently held
01/19/17 19:23:32 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9908.0.0)
01/19/17 19:23:37 Currently monitoring 1 Condor log file(s)
01/19/17 19:23:37 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node sessioncompute_0_ID0000003 (9908.0.0)
01/19/17 19:23:37 POST Script of Node sessioncompute_0_ID0000003 completed successfully.
01/19/17 19:23:37 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:23:37 Of 32 nodes total:
01/19/17 19:23:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:23:37   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:23:37    20       0        2       0       0         10        0
01/19/17 19:23:37 0 job proc(s) currently held
01/19/17 19:24:02 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:02 Event: ULOG_JOB_TERMINATED for Condor Node sessioncompute_2_ID0000005 (9909.0.0)
01/19/17 19:24:02 Number of idle job procs: 0
01/19/17 19:24:02 Node sessioncompute_2_ID0000005 job proc (9909.0.0) completed successfully.
01/19/17 19:24:02 Node sessioncompute_2_ID0000005 job completed
01/19/17 19:24:02 Running POST script of Node sessioncompute_2_ID0000005...
01/19/17 19:24:02 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:02 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:02 Of 32 nodes total:
01/19/17 19:24:02  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:02   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:02    20       0        1       1       0         10        0
01/19/17 19:24:02 0 job proc(s) currently held
01/19/17 19:24:02 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9909.0.0)
01/19/17 19:24:07 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:07 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node sessioncompute_2_ID0000005 (9909.0.0)
01/19/17 19:24:07 POST Script of Node sessioncompute_2_ID0000005 completed successfully.
01/19/17 19:24:07 Event: ULOG_JOB_TERMINATED for Condor Node sessioncompute_1_ID0000004 (9905.0.0)
01/19/17 19:24:07 Number of idle job procs: 0
01/19/17 19:24:07 Node sessioncompute_1_ID0000004 job proc (9905.0.0) completed successfully.
01/19/17 19:24:07 Node sessioncompute_1_ID0000004 job completed
01/19/17 19:24:07 Running POST script of Node sessioncompute_1_ID0000004...
01/19/17 19:24:07 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:07 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:07 Of 32 nodes total:
01/19/17 19:24:07  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:07   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:07    21       0        0       1       1          9        0
01/19/17 19:24:07 0 job proc(s) currently held
01/19/17 19:24:08 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9905.0.0)
01/19/17 19:24:12 Submitting Condor Node clean_up_local_level_5_1 job(s)...
01/19/17 19:24:12 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:12 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:12 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:12 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_5_1 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_5_1 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"sessioncompute_0_ID0000003,sessioncompute_2_ID0000005" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_5_1.sub
01/19/17 19:24:12 From submit: Submitting job(s).
01/19/17 19:24:12 From submit: 1 job(s) submitted to cluster 9910.
01/19/17 19:24:12 	assigned Condor ID (9910.0.0)
01/19/17 19:24:12 Just submitted 1 job this cycle...
01/19/17 19:24:12 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:12 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node sessioncompute_1_ID0000004 (9905.0.0)
01/19/17 19:24:12 POST Script of Node sessioncompute_1_ID0000004 completed successfully.
01/19/17 19:24:12 Reassigning the id of job clean_up_local_level_5_1 from (9910.0.0) to (9910.0.0)
01/19/17 19:24:12 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_5_1 (9910.0.0)
01/19/17 19:24:12 Number of idle job procs: 1
01/19/17 19:24:12 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:12 Of 32 nodes total:
01/19/17 19:24:12  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:12   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:12    22       0        1       0       4          5        0
01/19/17 19:24:12 0 job proc(s) currently held
01/19/17 19:24:17 Submitting Condor Node longestsession_2_ID0000008 job(s)...
01/19/17 19:24:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'longestsession_2_ID0000008 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'longestsession_2_ID0000008 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_3_0,stage_in_remote_local_3_0,sessioncompute_1_ID0000004,sessioncompute_0_ID0000003,sessioncompute_2_ID0000005" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/longestsession_2_ID0000008.sub
01/19/17 19:24:17 From submit: Submitting job(s).
01/19/17 19:24:17 From submit: 1 job(s) submitted to cluster 9911.
01/19/17 19:24:17 	assigned Condor ID (9911.0.0)
01/19/17 19:24:17 Submitting Condor Node longestsession_1_ID0000007 job(s)...
01/19/17 19:24:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'longestsession_1_ID0000007 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'longestsession_1_ID0000007 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_3_1,stage_in_remote_local_3_1,sessioncompute_1_ID0000004,sessioncompute_0_ID0000003,sessioncompute_2_ID0000005" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/longestsession_1_ID0000007.sub
01/19/17 19:24:17 From submit: Submitting job(s).
01/19/17 19:24:17 From submit: 1 job(s) submitted to cluster 9912.
01/19/17 19:24:17 	assigned Condor ID (9912.0.0)
01/19/17 19:24:17 Submitting Condor Node clean_up_local_level_5_0 job(s)...
01/19/17 19:24:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_5_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_5_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"sessioncompute_1_ID0000004,stage_out_local_local_1_0,stage_out_local_local_1_1,sessioncompute_0_ID0000003,sessioncompute_2_ID0000005" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_5_0.sub
01/19/17 19:24:17 From submit: Submitting job(s).
01/19/17 19:24:17 From submit: 1 job(s) submitted to cluster 9913.
01/19/17 19:24:17 	assigned Condor ID (9913.0.0)
01/19/17 19:24:17 Submitting Condor Node longestsession_0_ID0000006 job(s)...
01/19/17 19:24:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'longestsession_0_ID0000006 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'longestsession_0_ID0000006 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_3_0,stage_in_remote_local_3_0,sessioncompute_1_ID0000004,sessioncompute_0_ID0000003,sessioncompute_2_ID0000005" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/longestsession_0_ID0000006.sub
01/19/17 19:24:17 From submit: Submitting job(s).
01/19/17 19:24:17 From submit: 1 job(s) submitted to cluster 9914.
01/19/17 19:24:17 	assigned Condor ID (9914.0.0)
01/19/17 19:24:17 Just submitted 4 jobs this cycle...
01/19/17 19:24:17 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:17 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_5_1 (9910.0.0)
01/19/17 19:24:17 Number of idle job procs: 0
01/19/17 19:24:17 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_5_1 (9910.0.0)
01/19/17 19:24:17 Number of idle job procs: 0
01/19/17 19:24:17 Node clean_up_local_level_5_1 job proc (9910.0.0) completed successfully.
01/19/17 19:24:17 Node clean_up_local_level_5_1 job completed
01/19/17 19:24:17 Running POST script of Node clean_up_local_level_5_1...
01/19/17 19:24:17 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:17 Reassigning the id of job longestsession_2_ID0000008 from (9911.0.0) to (9911.0.0)
01/19/17 19:24:17 Event: ULOG_SUBMIT for Condor Node longestsession_2_ID0000008 (9911.0.0)
01/19/17 19:24:17 Number of idle job procs: 1
01/19/17 19:24:17 Reassigning the id of job longestsession_1_ID0000007 from (9912.0.0) to (9912.0.0)
01/19/17 19:24:17 Event: ULOG_SUBMIT for Condor Node longestsession_1_ID0000007 (9912.0.0)
01/19/17 19:24:17 Number of idle job procs: 2
01/19/17 19:24:17 Reassigning the id of job clean_up_local_level_5_0 from (9913.0.0) to (9913.0.0)
01/19/17 19:24:17 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_5_0 (9913.0.0)
01/19/17 19:24:17 Number of idle job procs: 3
01/19/17 19:24:17 Reassigning the id of job longestsession_0_ID0000006 from (9914.0.0) to (9914.0.0)
01/19/17 19:24:17 Event: ULOG_SUBMIT for Condor Node longestsession_0_ID0000006 (9914.0.0)
01/19/17 19:24:17 Number of idle job procs: 4
01/19/17 19:24:17 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:17 Of 32 nodes total:
01/19/17 19:24:17  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:17   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:17    22       0        4       1       0          5        0
01/19/17 19:24:17 0 job proc(s) currently held
01/19/17 19:24:18 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9910.0.0)
01/19/17 19:24:22 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:22 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_5_1 (9910.0.0)
01/19/17 19:24:22 POST Script of Node clean_up_local_level_5_1 completed successfully.
01/19/17 19:24:22 Event: ULOG_EXECUTE for Condor Node longestsession_2_ID0000008 (9911.0.0)
01/19/17 19:24:22 Number of idle job procs: 3
01/19/17 19:24:22 Event: ULOG_EXECUTE for Condor Node longestsession_1_ID0000007 (9912.0.0)
01/19/17 19:24:22 Number of idle job procs: 2
01/19/17 19:24:22 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:22 Of 32 nodes total:
01/19/17 19:24:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:22   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:22    23       0        4       0       0          5        0
01/19/17 19:24:22 0 job proc(s) currently held
01/19/17 19:24:27 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:27 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_5_0 (9913.0.0)
01/19/17 19:24:27 Number of idle job procs: 1
01/19/17 19:24:32 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:32 Event: ULOG_JOB_TERMINATED for Condor Node longestsession_1_ID0000007 (9912.0.0)
01/19/17 19:24:32 Number of idle job procs: 1
01/19/17 19:24:32 Node longestsession_1_ID0000007 job proc (9912.0.0) completed successfully.
01/19/17 19:24:32 Node longestsession_1_ID0000007 job completed
01/19/17 19:24:32 Running POST script of Node longestsession_1_ID0000007...
01/19/17 19:24:32 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:32 Event: ULOG_JOB_TERMINATED for Condor Node longestsession_2_ID0000008 (9911.0.0)
01/19/17 19:24:32 Number of idle job procs: 1
01/19/17 19:24:32 Node longestsession_2_ID0000008 job proc (9911.0.0) completed successfully.
01/19/17 19:24:32 Node longestsession_2_ID0000008 job completed
01/19/17 19:24:32 Running POST script of Node longestsession_2_ID0000008...
01/19/17 19:24:32 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:32 Event: ULOG_EXECUTE for Condor Node longestsession_0_ID0000006 (9914.0.0)
01/19/17 19:24:32 Number of idle job procs: 0
01/19/17 19:24:32 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_5_0 (9913.0.0)
01/19/17 19:24:32 Number of idle job procs: 0
01/19/17 19:24:32 Node clean_up_local_level_5_0 job proc (9913.0.0) completed successfully.
01/19/17 19:24:32 Node clean_up_local_level_5_0 job completed
01/19/17 19:24:32 Running POST script of Node clean_up_local_level_5_0...
01/19/17 19:24:32 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:32 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:32 Of 32 nodes total:
01/19/17 19:24:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:32   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:32    23       0        1       3       0          5        0
01/19/17 19:24:32 0 job proc(s) currently held
01/19/17 19:24:32 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9912.0.0)
01/19/17 19:24:32 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9911.0.0)
01/19/17 19:24:32 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9913.0.0)
01/19/17 19:24:37 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:37 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node longestsession_1_ID0000007 (9912.0.0)
01/19/17 19:24:37 POST Script of Node longestsession_1_ID0000007 completed successfully.
01/19/17 19:24:37 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node longestsession_2_ID0000008 (9911.0.0)
01/19/17 19:24:37 POST Script of Node longestsession_2_ID0000008 completed successfully.
01/19/17 19:24:37 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_5_0 (9913.0.0)
01/19/17 19:24:37 POST Script of Node clean_up_local_level_5_0 completed successfully.
01/19/17 19:24:37 Event: ULOG_JOB_TERMINATED for Condor Node longestsession_0_ID0000006 (9914.0.0)
01/19/17 19:24:37 Number of idle job procs: 0
01/19/17 19:24:37 Node longestsession_0_ID0000006 job proc (9914.0.0) completed successfully.
01/19/17 19:24:37 Node longestsession_0_ID0000006 job completed
01/19/17 19:24:37 Running POST script of Node longestsession_0_ID0000006...
01/19/17 19:24:37 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:37 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:37 Of 32 nodes total:
01/19/17 19:24:37  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:37   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:37    26       0        0       1       1          4        0
01/19/17 19:24:37 0 job proc(s) currently held
01/19/17 19:24:37 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9914.0.0)
01/19/17 19:24:42 Submitting Condor Node clean_up_local_level_6_0 job(s)...
01/19/17 19:24:42 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:42 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:42 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:42 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_6_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_6_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"longestsession_2_ID0000008,longestsession_1_ID0000007" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_6_0.sub
01/19/17 19:24:42 From submit: Submitting job(s).
01/19/17 19:24:42 From submit: 1 job(s) submitted to cluster 9915.
01/19/17 19:24:42 	assigned Condor ID (9915.0.0)
01/19/17 19:24:42 Just submitted 1 job this cycle...
01/19/17 19:24:42 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:42 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node longestsession_0_ID0000006 (9914.0.0)
01/19/17 19:24:42 POST Script of Node longestsession_0_ID0000006 completed successfully.
01/19/17 19:24:42 Reassigning the id of job clean_up_local_level_6_0 from (9915.0.0) to (9915.0.0)
01/19/17 19:24:42 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_6_0 (9915.0.0)
01/19/17 19:24:42 Number of idle job procs: 1
01/19/17 19:24:42 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:42 Of 32 nodes total:
01/19/17 19:24:42  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:42   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:42    27       0        1       0       2          2        0
01/19/17 19:24:42 0 job proc(s) currently held
01/19/17 19:24:47 Submitting Condor Node clean_up_local_level_6_1 job(s)...
01/19/17 19:24:47 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:47 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:47 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:47 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_6_1 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_6_1 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"longestsession_0_ID0000006" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_6_1.sub
01/19/17 19:24:47 From submit: Submitting job(s).
01/19/17 19:24:47 From submit: 1 job(s) submitted to cluster 9916.
01/19/17 19:24:47 	assigned Condor ID (9916.0.0)
01/19/17 19:24:47 Submitting Condor Node terminate_0_ID0000009 job(s)...
01/19/17 19:24:47 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:24:47 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:24:47 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:24:47 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'terminate_0_ID0000009 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'terminate_0_ID0000009 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"stage_in_local_local_4_0,stage_in_remote_local_4_0,longestsession_2_ID0000008,longestsession_1_ID0000007,longestsession_0_ID0000006" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/terminate_0_ID0000009.sub
01/19/17 19:24:47 From submit: Submitting job(s).
01/19/17 19:24:47 From submit: 1 job(s) submitted to cluster 9917.
01/19/17 19:24:47 	assigned Condor ID (9917.0.0)
01/19/17 19:24:47 Just submitted 2 jobs this cycle...
01/19/17 19:24:47 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:47 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_6_0 (9915.0.0)
01/19/17 19:24:47 Number of idle job procs: 0
01/19/17 19:24:47 Reassigning the id of job clean_up_local_level_6_1 from (9916.0.0) to (9916.0.0)
01/19/17 19:24:47 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_6_1 (9916.0.0)
01/19/17 19:24:47 Number of idle job procs: 1
01/19/17 19:24:47 Reassigning the id of job terminate_0_ID0000009 from (9917.0.0) to (9917.0.0)
01/19/17 19:24:47 Event: ULOG_SUBMIT for Condor Node terminate_0_ID0000009 (9917.0.0)
01/19/17 19:24:47 Number of idle job procs: 2
01/19/17 19:24:47 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:47 Of 32 nodes total:
01/19/17 19:24:47  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:47   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:47    27       0        3       0       0          2        0
01/19/17 19:24:47 0 job proc(s) currently held
01/19/17 19:24:52 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:52 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_6_1 (9916.0.0)
01/19/17 19:24:52 Number of idle job procs: 1
01/19/17 19:24:52 Event: ULOG_EXECUTE for Condor Node terminate_0_ID0000009 (9917.0.0)
01/19/17 19:24:52 Number of idle job procs: 0
01/19/17 19:24:52 Event: ULOG_JOB_TERMINATED for Condor Node terminate_0_ID0000009 (9917.0.0)
01/19/17 19:24:52 Number of idle job procs: 0
01/19/17 19:24:52 Node terminate_0_ID0000009 job proc (9917.0.0) completed successfully.
01/19/17 19:24:52 Node terminate_0_ID0000009 job completed
01/19/17 19:24:52 Running POST script of Node terminate_0_ID0000009...
01/19/17 19:24:52 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:52 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_6_0 (9915.0.0)
01/19/17 19:24:52 Number of idle job procs: 0
01/19/17 19:24:52 Node clean_up_local_level_6_0 job proc (9915.0.0) completed successfully.
01/19/17 19:24:52 Node clean_up_local_level_6_0 job completed
01/19/17 19:24:52 Running POST script of Node clean_up_local_level_6_0...
01/19/17 19:24:52 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:52 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_6_1 (9916.0.0)
01/19/17 19:24:52 Number of idle job procs: 0
01/19/17 19:24:52 Node clean_up_local_level_6_1 job proc (9916.0.0) completed successfully.
01/19/17 19:24:52 Node clean_up_local_level_6_1 job completed
01/19/17 19:24:52 Running POST script of Node clean_up_local_level_6_1...
01/19/17 19:24:52 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:24:52 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:52 Of 32 nodes total:
01/19/17 19:24:52  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:52   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:52    27       0        0       3       0          2        0
01/19/17 19:24:52 0 job proc(s) currently held
01/19/17 19:24:53 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9916.0.0)
01/19/17 19:24:53 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9917.0.0)
01/19/17 19:24:53 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9915.0.0)
01/19/17 19:24:57 Currently monitoring 1 Condor log file(s)
01/19/17 19:24:57 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_6_1 (9916.0.0)
01/19/17 19:24:57 POST Script of Node clean_up_local_level_6_1 completed successfully.
01/19/17 19:24:57 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node terminate_0_ID0000009 (9917.0.0)
01/19/17 19:24:57 POST Script of Node terminate_0_ID0000009 completed successfully.
01/19/17 19:24:57 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_6_0 (9915.0.0)
01/19/17 19:24:57 POST Script of Node clean_up_local_level_6_0 completed successfully.
01/19/17 19:24:57 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:24:57 Of 32 nodes total:
01/19/17 19:24:57  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:24:57   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:24:57    30       0        0       0       1          1        0
01/19/17 19:24:57 0 job proc(s) currently held
01/19/17 19:25:02 Submitting Condor Node clean_up_local_level_7_0 job(s)...
01/19/17 19:25:02 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:25:02 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:25:02 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:25:02 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'clean_up_local_level_7_0 -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'clean_up_local_level_7_0 -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"terminate_0_ID0000009" -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never 00/00/clean_up_local_level_7_0.sub
01/19/17 19:25:02 From submit: Submitting job(s).
01/19/17 19:25:02 From submit: 1 job(s) submitted to cluster 9918.
01/19/17 19:25:02 	assigned Condor ID (9918.0.0)
01/19/17 19:25:02 Just submitted 1 job this cycle...
01/19/17 19:25:02 Currently monitoring 1 Condor log file(s)
01/19/17 19:25:02 Reassigning the id of job clean_up_local_level_7_0 from (9918.0.0) to (9918.0.0)
01/19/17 19:25:02 Event: ULOG_SUBMIT for Condor Node clean_up_local_level_7_0 (9918.0.0)
01/19/17 19:25:02 Number of idle job procs: 1
01/19/17 19:25:02 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:25:02 Of 32 nodes total:
01/19/17 19:25:02  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:25:02   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:25:02    30       0        1       0       0          1        0
01/19/17 19:25:02 0 job proc(s) currently held
01/19/17 19:25:07 Currently monitoring 1 Condor log file(s)
01/19/17 19:25:07 Event: ULOG_EXECUTE for Condor Node clean_up_local_level_7_0 (9918.0.0)
01/19/17 19:25:07 Number of idle job procs: 0
01/19/17 19:25:07 Event: ULOG_JOB_TERMINATED for Condor Node clean_up_local_level_7_0 (9918.0.0)
01/19/17 19:25:07 Number of idle job procs: 0
01/19/17 19:25:07 Node clean_up_local_level_7_0 job proc (9918.0.0) completed successfully.
01/19/17 19:25:07 Node clean_up_local_level_7_0 job completed
01/19/17 19:25:07 Running POST script of Node clean_up_local_level_7_0...
01/19/17 19:25:07 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:25:07 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:25:07 Of 32 nodes total:
01/19/17 19:25:07  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:25:07   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:25:07    30       0        0       1       0          1        0
01/19/17 19:25:07 0 job proc(s) currently held
01/19/17 19:25:07 Initializing user log writer for /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log, (9918.0.0)
01/19/17 19:25:12 Currently monitoring 1 Condor log file(s)
01/19/17 19:25:12 Event: ULOG_POST_SCRIPT_TERMINATED for Condor Node clean_up_local_level_7_0 (9918.0.0)
01/19/17 19:25:12 POST Script of Node clean_up_local_level_7_0 completed successfully.
01/19/17 19:25:12 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:25:12 Of 32 nodes total:
01/19/17 19:25:12  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:25:12   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:25:12    31       0        0       0       1          0        0
01/19/17 19:25:12 0 job proc(s) currently held
01/19/17 19:25:17 Submitting Condor Node cleanup_example_workflow_0_local job(s)...
01/19/17 19:25:17 Adding a DAGMan workflow log /home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log
01/19/17 19:25:17 Masking the events recorded in the DAGMAN workflow log
01/19/17 19:25:17 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
01/19/17 19:25:17 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'cleanup_example_workflow_0_local -a +DAGManJobId' '=' '9887 -a DAGManJobId' '=' '9887 -a submit_event_notes' '=' 'DAG' 'Node:' 'cleanup_example_workflow_0_local -a dagman_log' '=' '/home/ubuntu/wikiflow/3_wikiflow_1sh_1s_annot/dags/ubuntu/pegasus/example_workflow/20170119T180536+0000/./example_workflow-0.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +DAGParentNodeNames' '=' '"clean_up_local_level_3_0,clean_up_local_level_4_0,clean_up_local_level_5_0,clean_up_local_level_5_1,clean_up_local_level_6_0,clean_up_local_level_6_1,clean_up_local_level_7_0" -a notification' '=' 'never 00/00/cleanup_example_workflow_0_local.sub
01/19/17 19:25:17 From submit: Submitting job(s).
01/19/17 19:25:17 From submit: 1 job(s) submitted to cluster 9919.
01/19/17 19:25:17 	assigned Condor ID (9919.0.0)
01/19/17 19:25:17 Just submitted 1 job this cycle...
01/19/17 19:25:17 Currently monitoring 1 Condor log file(s)
01/19/17 19:25:17 Reassigning the id of job cleanup_example_workflow_0_local from (9919.0.0) to (9919.0.0)
01/19/17 19:25:17 Event: ULOG_SUBMIT for Condor Node cleanup_example_workflow_0_local (9919.0.0)
01/19/17 19:25:17 Number of idle job procs: 1
01/19/17 19:25:17 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:25:17 Of 32 nodes total:
01/19/17 19:25:17  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:25:17   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:25:17    31       0        1       0       0          0        0
01/19/17 19:25:17 0 job proc(s) currently held
01/19/17 19:25:22 Currently monitoring 1 Condor log file(s)
01/19/17 19:25:22 Event: ULOG_EXECUTE for Condor Node cleanup_example_workflow_0_local (9919.0.0)
01/19/17 19:25:22 Number of idle job procs: 0
01/19/17 19:25:22 Event: ULOG_JOB_TERMINATED for Condor Node cleanup_example_workflow_0_local (9919.0.0)
01/19/17 19:25:22 Number of idle job procs: 0
01/19/17 19:25:22 Node cleanup_example_workflow_0_local job proc (9919.0.0) completed successfully.
01/19/17 19:25:22 Node cleanup_example_workflow_0_local job completed
01/19/17 19:25:22 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:25:22 Of 32 nodes total:
01/19/17 19:25:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:25:22   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:25:22    32       0        0       0       0          0        0
01/19/17 19:25:22 0 job proc(s) currently held
01/19/17 19:25:22 All jobs Completed!
01/19/17 19:25:22 Note: 0 total job deferrals because of -MaxJobs limit (0)
01/19/17 19:25:22 Note: 0 total job deferrals because of -MaxIdle limit (1000)
01/19/17 19:25:22 Note: 0 total job deferrals because of node category throttles
01/19/17 19:25:22 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
01/19/17 19:25:22 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
01/19/17 19:25:22 DAG status: 0 (DAG_STATUS_OK)
01/19/17 19:25:22 Of 32 nodes total:
01/19/17 19:25:22  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
01/19/17 19:25:22   ===     ===      ===     ===     ===        ===      ===
01/19/17 19:25:22    32       0        0       0       0          0        0
01/19/17 19:25:22 0 job proc(s) currently held
01/19/17 19:25:22 Wrote metrics file example_workflow-0.dag.metrics.
01/19/17 19:25:22 Reporting metrics to Pegasus metrics server(s); output is in example_workflow-0.dag.metrics.out.
01/19/17 19:25:22 Running command </usr/lib/condor/libexec/condor_dagman_metrics_reporter -f example_workflow-0.dag.metrics -t 100>
01/19/17 19:25:22 Warning: mysin has length 0 (ignore if produced by DAGMan; see gittrac #4987, #5031)
01/19/17 19:25:22 **** condor_scheduniv_exec.9887.0 (condor_DAGMAN) pid 81893 EXITING WITH STATUS 0
